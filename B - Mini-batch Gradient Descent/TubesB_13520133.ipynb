{"cells":[{"cell_type":"code","source":"import math\nimport json\nimport random\nimport copy\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn import datasets, metrics\nimport pandas as pd\nimport numpy as np\niris = datasets.load_iris()\n\nX = iris['data']\ny = iris['target']\n\n# Combine the data and target arrays\ndata = np.hstack((X, y.reshape(-1, 1)))\n\n# Shuffle the data randomly\nnp.random.shuffle(data)\n\n# Separate the shuffled data and target arrays\nX = data[:, :-1]\ny = data[:, -1].astype(int)","metadata":{"cell_id":"bd0f78b375d349bd9279f61d46b5f608","source_hash":"7291e486","execution_start":1683294725702,"execution_millis":2607,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def linear(net):\n    return net\n\ndef relu(net):\n    return max(0, net)\n\ndef sigmoid(net):\n    try:\n        return 1 / (1 + math.exp((-1) * net))\n    except OverflowError:\n        return 0\n\ndef softmax(net):\n    try:\n        total_softmax = 0\n        for i in range(len(net)):\n            net[i] = math.exp(net[i])\n            total_softmax += net[i]\n        for i in range(len(net)):\n            net[i] = net[i] / total_softmax\n    except OverflowError: \n        for i in range(len(net)):\n            net[i] = 1\n    return net\n\ndef derive(x, type):\n    if (type == \"linear\"):\n        return 1\n    elif (type == \"relu\"):\n        #x is activated neuron\n        if (x > 0):\n            return 1\n        else:\n            return 0\n    elif (type == \"sigmoid\"):\n        return x * (1-x)\n\ndef deriveSoftmax(output, k, target):\n    idxTarget = target.index(max(target))\n    if idxTarget == k:\n        return -(1 - output[k])\n    else:\n        return output[k]\n\ndef loss(output, target, activation):\n    if (activation == \"softmax\"):\n        try:\n            return (-1) * math.log(output[target.index(max(target))])\n        except:\n            return 0\n    else:\n        total = 0\n        for i in range(len(output)):\n            total += (output[i] - target[i]) ** 2\n        return 0.5 * total\n\n\ndef classification(net, type):\n    if (type == \"linear\"):\n        return net\n    elif (type == \"sigmoid\"):\n        if (net > 0.5):\n            return \"Kelas Positif\"\n        else:\n            return \"Kelas Negatif\"\n    elif (type == \"reLU\"):\n        return net\n    elif (type == \"softmax\"):\n        return net.index(max(net))\n\ndef countSSE(output, expected):\n    res = 0\n    for i in range(len(output)):\n        temp = output[i][len(output)-1] - expected[i]\n        res += temp**2\n    return res","metadata":{"cell_id":"e70e1d490c3b42ae931f34f507049c34","source_hash":"f8b020a4","execution_start":1683294728368,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class ANN:\n    def readInput(self, activation, layer, neuron_each_layer, inp, weight, target, learning_rate, batch_size, max_iter, error_threshold):\n        self.activation = activation\n        self.layer = layer \n        self.neuron_each_layer = neuron_each_layer\n        self.inp = inp\n        self.weight = weight\n        self.target = target\n        self.learning_rate = learning_rate\n        self.batch_size = batch_size\n        self.max_iter = max_iter\n        self.error_threshold = error_threshold\n        self.loss= []\n        self.delta_weight = copy.deepcopy(self.weight)\n\n\n    def readFile(self, file):\n        f = open(file, \"r\")\n        data = json.load(f)\n        case = data[\"case\"]\n\n        self.activation = []\n        for i in case[\"model\"][\"layers\"]:\n            self.activation.append(i['activation_function'])\n        self.layer = len(case[\"model\"][\"layers\"])\n        self.neuron_each_layer = [case[\"model\"][\"input_size\"]]\n        for i in case[\"model\"][\"layers\"]:\n            self.neuron_each_layer.append(i['number_of_neurons'])\n        self.inp = case[\"input\"]\n        self.weight = case[\"initial_weights\"]\n        self.target = case[\"target\"]\n        self.learning_rate = case[\"learning_parameters\"][\"learning_rate\"]\n        self.batch_size = case[\"learning_parameters\"][\"batch_size\"]\n        self.max_iter = case[\"learning_parameters\"][\"max_iteration\"]\n        self.error_threshold = case[\"learning_parameters\"][\"error_threshold\"]\n        \n        expect = data[\"expect\"]\n        if (\"final_weights\" in expect):\n            self.expected = expect[\"final_weights\"]\n        self.loss= []\n        self.stopped_by = expect[\"stopped_by\"]\n        self.delta_weight = copy.deepcopy(self.weight)\n\n    def generateWeight(self):\n        for i in range(len(self.weight)):\n            for j in range(len(self.weight[i])):\n                for k in range(len(self.weight[i][j])):\n                    self.weight[i][j][k] = random.randint(-100, 100) / 100 * 0.5\n\n    def forwardProp(self, inp):\n        instance = 0\n        err = []\n        for x in range(len(inp)):\n            print(\"\\nInstance:\", inp[x])\n            h = [inp[x]]\n            for i in range(len(self.weight)):\n                h.append([0 for j in range(self.neuron_each_layer[i + 1])])\n                net = [0 for j in range(self.neuron_each_layer[i + 1])]\n                for k in range(len(self.weight[i][0])):\n                    net[k] += self.weight[i][0][k]\n                for j in range(1, len(self.weight[i])):\n                    for k in range(len(self.weight[i][j])):\n                        net[k] += h[i][j - 1] * self.weight[i][j][k]\n                \n                if self.activation[i] == \"softmax\":\n                    h[i+1] = eval(self.activation[i] + \"({})\".format(net))\n                else:\n                    for j in range(len(net)):\n                        h[i + 1][j] = eval(self.activation[i] + \"({})\".format(net[j]))\n            err_each = loss(h[len(h) - 1], self.target[x], self.activation[-1])\n            err.append(err_each)\n            print(\"Error:\", err_each)\n            print(\"Output:\", h[len(h) - 1])\n            print(\"Hidden Layer:\", h)\n            self.output.append(h[len(h) - 1])\n            self.hidden_layer.append(h)\n            instance += 1\n        avg_error = np.average(err)\n        print(\"Average of Error: \", avg_error)\n        return avg_error\n\n    def gradient(self, index, level, j, k, is_leaf):\n        if (self.activation[level] == \"softmax\"):\n            d_layer_net = deriveSoftmax(self.hidden_layer[index][level+1], k, self.target[index])\n        else:\n            d_layer_net = derive(self.hidden_layer[index][level+1][k], self.activation[level])\n        if (is_leaf):\n            if (j - 1 < 0):\n                d_net_value = 1\n            else:\n                d_net_value = self.hidden_layer[index][level][j - 1]              \n        else:\n            d_net_value = self.weight[level][j][k] \n        if (level + 1 == len(self.hidden_layer[index]) - 1):\n            d_E_o = (-1) * (self.target[index][k] - self.output[index][k])\n            if (self.activation[level] != \"softmax\"):\n                return d_E_o * d_layer_net * d_net_value\n            else:\n                return d_layer_net * d_net_value\n        else:\n            parent_gradient = 0\n            for m in range(len(self.weight[level + 1][k+1])):\n                parent_gradient += self.gradient(index, level + 1, k+1, m, False)\n            return d_layer_net * d_net_value * parent_gradient\n\n    def backwardProp(self, start, end, count):\n        print(\"Initial weight:\")\n        print(np.array(self.weight))\n        print(\"Epoch -\", count+1)\n        print(\"-------------------------------\")\n        err = self.forwardProp(self.inp[start:end])\n        is_backward = True;\n        if (err <= self.error_threshold):\n            print(\"Stopped by error_treshold\")\n            is_backward = False;\n        if is_backward:\n            self.delta_weight_all = []\n            for index in range(len(self.output)):\n                self.delta_weight = copy.deepcopy(self.weight)\n                for i in range(len(self.weight) - 1, -1, - 1):\n                    for j in range(len(self.weight[i])):\n                        for k in range(len(self.weight[i][j])):\n                            self.delta_weight[i][j][k] = self.gradient(index, i, j, k, True)\n                self.delta_weight_all.append(self.delta_weight)\n            for i in range(len(self.delta_weight_all[0])):\n                for j in range(len(self.delta_weight_all[0][i])):\n                    for k in range(len(self.delta_weight_all[0][i][j])):\n                        total_weight = 0 \n                        for l in range(len(self.delta_weight_all)):\n                            total_weight += self.delta_weight_all[l][i][j][k]\n                        self.weight[i][j][k] -= self.learning_rate * total_weight\n            print(\"Final Weight:\")\n            print(np.array(self.weight))\n            print(\"\\nEnd of epoch -\", count + 1)\n            print(\"-------------------------------\")\n            return True\n        else:\n            return False\n    \n    def mini_batch(self):\n        isContinue = True\n        count = 0\n        while isContinue:\n            self.output=[]\n            self.hidden_layer=[]\n            self.loss= []\n            for i in range(0,len(self.inp),self.batch_size):\n                isContinue = self.backwardProp(i, i+self.batch_size, count)\n                if (not isContinue):\n                    break\n            count = count+1\n            if (count >= self.max_iter):\n                isContinue = False\n            if (not isContinue):\n                break\n    \n    def saveModel(self, file_name):\n        model_dictionary = {\n            \"case\": {\n                \"model\": {\n                    \"input_size\": self.neuron_each_layer[0] \n                },\n                \"input\": self.inp,\n                \"weights\": self.weight,\n            },\n            \"expect\": {\n                \"output\": self.target,\n                \"max_sse\": self.error_threshold\n            }\n        }\n        model_dictionary[\"case\"][\"model\"][\"layers\"] = []\n        for idx, activation_function in enumerate(self.activation):\n            model_dictionary[\"case\"][\"model\"][\"layers\"].append({\n                \"number_of_neurons\": self.neuron_each_layer[idx + 1],\n                \"activation_function\": activation_function\n            })\n        json_object = json.dumps(model_dictionary, indent=4)\n        with open(file_name, \"w\") as savefile:\n            savefile.write(json_object)\n    ","metadata":{"cell_id":"c057d464ac424aa7b693cbce4758f44e","source_hash":"19df76c","execution_start":1683294728369,"execution_millis":52,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":3},{"cell_type":"code","source":"file = \"sigmoid_mini_batch_GD.JSON\"\n\nann = ANN()\nann.readFile(\"test/{}\".format(file))\nann.mini_batch()\nann.saveModel(\"output/{}\".format(file))","metadata":{"cell_id":"4bb8814b6871428599bf3a53151f4a58","source_hash":"b6e9b469","execution_start":1683294728512,"execution_millis":11472,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"  [-3.12903193 -7.93857454]]]\nEpoch - 2450\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651427526719427\nOutput: [0.8262456510201048, 0.9465887678641521]\nHidden Layer: [[1.0, 0.0], [0.8262456510201048, 0.9465887678641521]]\n\nInstance: [1.0, 1.0]\nError: 0.3426068941424451\nOutput: [0.17224742701861426, 0.006282213589645244]\nHidden Layer: [[1.0, 1.0], [0.17224742701861426, 0.006282213589645244]]\nAverage of Error:  0.3038748234071939\nFinal Weight:\n[[[ 0.39716091  0.40264748]\n  [ 1.16214742  2.47264135]\n  [-3.13029247 -7.9395494 ]]]\n\nEnd of epoch - 2450\n-------------------------------\nInitial weight:\n[[[ 0.39716091  0.40264748]\n  [ 1.16214742  2.47264135]\n  [-3.13029247 -7.9395494 ]]]\nEpoch - 2451\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20427546035710836\nOutput: [0.5980053485648965, 0.5993235800362434]\nHidden Layer: [[0.0, 0.0], [0.5980053485648965, 0.5993235800362434]]\n\nInstance: [0.0, 0.1]\nError: 0.1960774989781995\nOutput: [0.5210205194413424, 0.40340259686838603]\nHidden Layer: [[0.0, 0.1], [0.5210205194413424, 0.40340259686838603]]\nAverage of Error:  0.20017647966765395\nFinal Weight:\n[[[ 0.39714244  0.40256047]\n  [ 1.16214742  2.47264135]\n  [-3.12909714 -7.94052027]]]\n\nEnd of epoch - 2451\n-------------------------------\nInitial weight:\n[[[ 0.39714244  0.40256047]\n  [ 1.16214742  2.47264135]\n  [-3.12909714 -7.94052027]]]\nEpoch - 2451\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651459816159394\nOutput: [0.8262514282674692, 0.9466068714969829]\nHidden Layer: [[1.0, 0.0], [0.8262514282674692, 0.9466068714969829]]\n\nInstance: [1.0, 1.0]\nError: 0.3426097789356659\nOutput: [0.17224386683399093, 0.006272310370832805]\nHidden Layer: [[1.0, 1.0], [0.17224386683399093, 0.006272310370832805]]\nAverage of Error:  0.30387788027580265\nFinal Weight:\n[[[ 0.39716252  0.40273941]\n  [ 1.16218597  2.4729073 ]\n  [-3.13035759 -7.94149504]]]\n\nEnd of epoch - 2451\n-------------------------------\nInitial weight:\n[[[ 0.39716252  0.40273941]\n  [ 1.16218597  2.4729073 ]\n  [-3.13035759 -7.94149504]]]\nEpoch - 2452\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20426680751569626\nOutput: [0.5980057339092627, 0.5993456551778215]\nHidden Layer: [[0.0, 0.0], [0.5980057339092627, 0.5993456551778215]]\n\nInstance: [0.0, 0.1]\nError: 0.19606812168845827\nOutput: [0.5210192943965954, 0.4033778960684153]\nHidden Layer: [[0.0, 0.1], [0.5210192943965954, 0.4033778960684153]]\nAverage of Error:  0.20016746460207727\nFinal Weight:\n[[[ 0.39714407  0.40265248]\n  [ 1.16218597  2.4729073 ]\n  [-3.12916225 -7.94246583]]]\n\nEnd of epoch - 2452\n-------------------------------\nInitial weight:\n[[[ 0.39714407  0.40265248]\n  [ 1.16218597  2.4729073 ]\n  [-3.12916225 -7.94246583]]]\nEpoch - 2452\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26514920533559166\nOutput: [0.8262571967722265, 0.9466249608175243]\nHidden Layer: [[1.0, 0.0], [0.8262571967722265, 0.9466249608175243]]\n\nInstance: [1.0, 1.0]\nError: 0.342612659436191\nOutput: [0.17224031208649396, 0.006262422671548782]\nHidden Layer: [[1.0, 1.0], [0.17224031208649396, 0.006262422671548782]]\nAverage of Error:  0.3038809323858913\nFinal Weight:\n[[[ 0.39716412  0.40283134]\n  [ 1.16222446  2.47317308]\n  [-3.13042261 -7.94344051]]]\n\nEnd of epoch - 2452\n-------------------------------\nInitial weight:\n[[[ 0.39716412  0.40283134]\n  [ 1.16222446  2.47317308]\n  [-3.13042261 -7.94344051]]]\nEpoch - 2453\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20425815533812092\nOutput: [0.5980061186961886, 0.599367729186228]\nHidden Layer: [[0.0, 0.0], [0.5980061186961886, 0.599367729186228]]\n\nInstance: [0.0, 0.1]\nError: 0.19605874567259857\nOutput: [0.5210180712043588, 0.4033531991101651]\nHidden Layer: [[0.0, 0.1], [0.5210180712043588, 0.4033531991101651]]\nAverage of Error:  0.20015845050535974\nFinal Weight:\n[[[ 0.3971457   0.40274449]\n  [ 1.16222446  2.47317308]\n  [-3.12922727 -7.94441122]]]\n\nEnd of epoch - 2453\n-------------------------------\nInitial weight:\n[[[ 0.3971457   0.40274449]\n  [ 1.16222446  2.47317308]\n  [-3.12922727 -7.94441122]]]\nEpoch - 2453\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.265152423839022\nOutput: [0.8262629565481278, 0.9466430358433301]\nHidden Layer: [[1.0, 0.0], [0.8262629565481278, 0.9466430358433301]]\n\nInstance: [1.0, 1.0]\nError: 0.3426155356505471\nOutput: [0.17223676276743558, 0.006252550468367218]\nHidden Layer: [[1.0, 1.0], [0.17223676276743558, 0.006252550468367218]]\nAverage of Error:  0.30388397974478454\nFinal Weight:\n[[[ 0.39716572  0.40292326]\n  [ 1.1622629   2.47343871]\n  [-3.13048753 -7.94538581]]]\n\nEnd of epoch - 2453\n-------------------------------\nInitial weight:\n[[[ 0.39716572  0.40292326]\n  [ 1.1622629   2.47343871]\n  [-3.13048753 -7.94538581]]]\nEpoch - 2454\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.2042495038250589\nOutput: [0.5980065029264722, 0.5993898020605772]\nHidden Layer: [[0.0, 0.0], [0.5980065029264722, 0.5993898020605772]]\n\nInstance: [0.0, 0.1]\nError: 0.19604937093078872\nOutput: [0.5210168498617201, 0.40332850599131664]\nHidden Layer: [[0.0, 0.1], [0.5210168498617201, 0.40332850599131664]]\nAverage of Error:  0.20014943737792382\nFinal Weight:\n[[[ 0.39714732  0.40283649]\n  [ 1.1622629   2.47343871]\n  [-3.12929219 -7.94635644]]]\n\nEnd of epoch - 2454\n-------------------------------\nInitial weight:\n[[[ 0.39714732  0.40283649]\n  [ 1.1622629   2.47343871]\n  [-3.12929219 -7.94635644]]]\nEpoch - 2454\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26515563713433915\nOutput: [0.8262687076089004, 0.9466610965919254]\nHidden Layer: [[1.0, 0.0], [0.8262687076089004, 0.9466610965919254]]\n\nInstance: [1.0, 1.0]\nError: 0.34261840758525075\nOutput: [0.17223321886814255, 0.006242693737894332]\nHidden Layer: [[1.0, 1.0], [0.17223321886814255, 0.006242693737894332]]\nAverage of Error:  0.3038870223597949\nFinal Weight:\n[[[ 0.39716731  0.40301518]\n  [ 1.16230128  2.47370416]\n  [-3.13055236 -7.94733094]]]\n\nEnd of epoch - 2454\n-------------------------------\nInitial weight:\n[[[ 0.39716731  0.40301518]\n  [ 1.16230128  2.47370416]\n  [-3.13055236 -7.94733094]]]\nEpoch - 2455\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20424085297718636\nOutput: [0.5980068866009107, 0.5994118737999835]\nHidden Layer: [[0.0, 0.0], [0.5980068866009107, 0.5994118737999835]]\n\nInstance: [0.0, 0.1]\nError: 0.19603999746319617\nOutput: [0.5210156303657723, 0.4033038167095544]\nHidden Layer: [[0.0, 0.1], [0.5210156303657723, 0.4033038167095544]]\nAverage of Error:  0.20014042522019126\nFinal Weight:\n[[[ 0.39714895  0.40292849]\n  [ 1.16230128  2.47370416]\n  [-3.12935701 -7.94830149]]]\n\nEnd of epoch - 2455\n-------------------------------\nInitial weight:\n[[[ 0.39714895  0.40292849]\n  [ 1.16230128  2.47370416]\n  [-3.12935701 -7.94830149]]]\nEpoch - 2455\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26515884522963984\nOutput: [0.8262744499682491, 0.9466791430808082]\nHidden Layer: [[1.0, 0.0], [0.8262744499682491, 0.9466791430808082]]\n\nInstance: [1.0, 1.0]\nError: 0.3426212752468079\nOutput: [0.1722296803799571, 0.006232852456768487]\nHidden Layer: [[1.0, 1.0], [0.1722296803799571, 0.006232852456768487]]\nAverage of Error:  0.30389006023822385\nFinal Weight:\n[[[ 0.39716891  0.4031071 ]\n  [ 1.1623396   2.47396945]\n  [-3.13061709 -7.9492759 ]]]\n\nEnd of epoch - 2455\n-------------------------------\nInitial weight:\n[[[ 0.39716891  0.4031071 ]\n  [ 1.1623396   2.47396945]\n  [-3.13061709 -7.9492759 ]]]\nEpoch - 2456\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.2042322027951783\nOutput: [0.5980072697203002, 0.5994339444035618]\nHidden Layer: [[0.0, 0.0], [0.5980072697203002, 0.5994339444035618]]\n\nInstance: [0.0, 0.1]\nError: 0.1960306252699878\nOutput: [0.5210144127136127, 0.40327913126256637]\nHidden Layer: [[0.0, 0.1], [0.5210144127136127, 0.40327913126256637]]\nAverage of Error:  0.20013141403258305\nFinal Weight:\n[[[ 0.39715057  0.40302049]\n  [ 1.1623396   2.47396945]\n  [-3.12942174 -7.95024637]]]\n\nEnd of epoch - 2456\n-------------------------------\nInitial weight:\n[[[ 0.39715057  0.40302049]\n  [ 1.1623396   2.47396945]\n  [-3.12942174 -7.95024637]]]\nEpoch - 2456\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651620481330074\nOutput: [0.8262801836398554, 0.9466971753274491]\nHidden Layer: [[1.0, 0.0], [0.8262801836398554, 0.9466971753274491]]\n\nInstance: [1.0, 1.0]\nError: 0.34262413864171437\nOutput: [0.17222614729423605, 0.006223026601660134]\nHidden Layer: [[1.0, 1.0], [0.17222614729423605, 0.006223026601660134]]\nAverage of Error:  0.3038930933873609\nFinal Weight:\n[[[ 0.3971705   0.40319901]\n  [ 1.16237787  2.47423458]\n  [-3.13068172 -7.95122069]]]\n\nEnd of epoch - 2456\n-------------------------------\nInitial weight:\n[[[ 0.3971705   0.40319901]\n  [ 1.16237787  2.47423458]\n  [-3.13068172 -7.95122069]]]\nEpoch - 2457\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20422355327970926\nOutput: [0.5980076522854354, 0.5994560138704272]\nHidden Layer: [[0.0, 0.0], [0.5980076522854354, 0.5994560138704272]]\n\nInstance: [0.0, 0.1]\nError: 0.19602125435132983\nOutput: [0.521013196902344, 0.40325444964804424]\nHidden Layer: [[0.0, 0.1], [0.521013196902344, 0.40325444964804424]]\nAverage of Error:  0.20012240381551955\nFinal Weight:\n[[[ 0.39715219  0.40311249]\n  [ 1.16237787  2.47423458]\n  [-3.12948637 -7.95219108]]]\n\nEnd of epoch - 2457\n-------------------------------\nInitial weight:\n[[[ 0.39715219  0.40311249]\n  [ 1.16237787  2.47423458]\n  [-3.12948637 -7.95219108]]]\nEpoch - 2457\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651652458525126\nOutput: [0.8262859086373779, 0.9467151933492906]\nHidden Layer: [[1.0, 0.0], [0.8262859086373779, 0.9467151933492906]]\n\nInstance: [1.0, 1.0]\nError: 0.3426269977764556\nOutput: [0.17222261960235136, 0.006213216149271826]\nHidden Layer: [[1.0, 1.0], [0.17222261960235136, 0.006213216149271826]]\nAverage of Error:  0.3038961218144841\nFinal Weight:\n[[[ 0.39717209  0.40329092]\n  [ 1.16241608  2.47449954]\n  [-3.13074626 -7.95316531]]]\n\nEnd of epoch - 2457\n-------------------------------\nInitial weight:\n[[[ 0.39717209  0.40329092]\n  [ 1.16241608  2.47449954]\n  [-3.13074626 -7.95316531]]]\nEpoch - 2458\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.2042149044314529\nOutput: [0.5980080342971104, 0.5994780821996955]\nHidden Layer: [[0.0, 0.0], [0.5980080342971104, 0.5994780821996955]]\n\nInstance: [0.0, 0.1]\nError: 0.19601188470738778\nOutput: [0.5210119829290738, 0.4032297718636828]\nHidden Layer: [[0.0, 0.1], [0.5210119829290738, 0.4032297718636828]]\nAverage of Error:  0.20011339456942034\nFinal Weight:\n[[[ 0.3971538   0.40320448]\n  [ 1.16241608  2.47449954]\n  [-3.1295509  -7.95413563]]]\n\nEnd of epoch - 2458\n-------------------------------\nInitial weight:\n[[[ 0.3971538   0.40320448]\n  [ 1.16241608  2.47449954]\n  [-3.1295509  -7.95413563]]]\nEpoch - 2458\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.265168438396213\nOutput: [0.8262916249744519, 0.9467331971637479]\nHidden Layer: [[1.0, 0.0], [0.8262916249744519, 0.9467331971637479]]\n\nInstance: [1.0, 1.0]\nError: 0.34262985265750656\nOutput: [0.1722190972956897, 0.006203421076338136]\nHidden Layer: [[1.0, 1.0], [0.1722190972956897, 0.006203421076338136]]\nAverage of Error:  0.3038991455268598\nFinal Weight:\n[[[ 0.39717367  0.40338283]\n  [ 1.16245423  2.47476434]\n  [-3.1308107  -7.95510977]]]\n\nEnd of epoch - 2458\n-------------------------------\nInitial weight:\n[[[ 0.39717367  0.40338283]\n  [ 1.16245423  2.47476434]\n  [-3.1308107  -7.95510977]]]\nEpoch - 2459\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.2042062562510821\nOutput: [0.5980084157561177, 0.5995001493904824]\nHidden Layer: [[0.0, 0.0], [0.5980084157561177, 0.5995001493904824]]\n\nInstance: [0.0, 0.1]\nError: 0.19600251633832672\nOutput: [0.521010770790914, 0.40320509790718057]\nHidden Layer: [[0.0, 0.1], [0.521010770790914, 0.40320509790718057]]\nAverage of Error:  0.2001043862947044\nFinal Weight:\n[[[ 0.39715542  0.40329647]\n  [ 1.16245423  2.47476434]\n  [-3.12961534 -7.95608   ]]]\n\nEnd of epoch - 2459\n-------------------------------\nInitial weight:\n[[[ 0.39715542  0.40329647]\n  [ 1.16245423  2.47476434]\n  [-3.12961534 -7.95608   ]]]\nEpoch - 2459\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651716257721538\nOutput: [0.82629733266469, 0.9467511867882089]\nHidden Layer: [[1.0, 0.0], [0.82629733266469, 0.9467511867882089]]\n\nInstance: [1.0, 1.0]\nError: 0.3426327032913324\nOutput: [0.1722155803656528, 0.006193641359625637]\nHidden Layer: [[1.0, 1.0], [0.1722155803656528, 0.006193641359625637]]\nAverage of Error:  0.3039021645317431\nFinal Weight:\n[[[ 0.39717526  0.40347473]\n  [ 1.16249232  2.47502897]\n  [-3.13087504 -7.95705405]]]\n\nEnd of epoch - 2459\n-------------------------------\nInitial weight:\n[[[ 0.39717526  0.40347473]\n  [ 1.16249232  2.47502897]\n  [-3.13087504 -7.95705405]]]\nEpoch - 2460\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20419760873926895\nOutput: [0.5980087966632491, 0.5995222154419043]\nHidden Layer: [[0.0, 0.0], [0.5980087966632491, 0.5995222154419043]]\n\nInstance: [0.0, 0.1]\nError: 0.19599314924431083\nOutput: [0.5210095604849819, 0.40318042777623947]\nHidden Layer: [[0.0, 0.1], [0.5210095604849819, 0.40318042777623947]]\nAverage of Error:  0.2000953789917899\nFinal Weight:\n[[[ 0.39715703  0.40338845]\n  [ 1.16249232  2.47502897]\n  [-3.12967968 -7.95802421]]]\n\nEnd of epoch - 2460\n-------------------------------\nInitial weight:\n[[[ 0.39715703  0.40338845]\n  [ 1.16249232  2.47502897]\n  [-3.12967968 -7.95802421]]]\nEpoch - 2460\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26517480798836685\nOutput: [0.8263030317216815, 0.9467691622400345]\nHidden Layer: [[1.0, 0.0], [0.8263030317216815, 0.9467691622400345]]\n\nInstance: [1.0, 1.0]\nError: 0.34263554968438764\nOutput: [0.17221206880365686, 0.006183876975932876]\nHidden Layer: [[1.0, 1.0], [0.17221206880365686, 0.006183876975932876]]\nAverage of Error:  0.30390517883637724\nFinal Weight:\n[[[ 0.39717684  0.40356664]\n  [ 1.16253036  2.47529344]\n  [-3.13093929 -7.95899816]]]\n\nEnd of epoch - 2460\n-------------------------------\nInitial weight:\n[[[ 0.39717684  0.40356664]\n  [ 1.16253036  2.47529344]\n  [-3.13093929 -7.95899816]]]\nEpoch - 2461\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20418896189668484\nOutput: [0.598009177019295, 0.599544280353078]\nHidden Layer: [[0.0, 0.0], [0.598009177019295, 0.599544280353078]]\n\nInstance: [0.0, 0.1]\nError: 0.1959837834255037\nOutput: [0.5210083520083996, 0.4031557614685646]\nHidden Layer: [[0.0, 0.1], [0.5210083520083996, 0.4031557614685646]]\nAverage of Error:  0.20008637266109427\nFinal Weight:\n[[[ 0.39715864  0.40348043]\n  [ 1.16253036  2.47529344]\n  [-3.12974392 -7.95996824]]]\n\nEnd of epoch - 2461\n-------------------------------\nInitial weight:\n[[[ 0.39715864  0.40348043]\n  [ 1.16253036  2.47529344]\n  [-3.12974392 -7.95996824]]]\nEpoch - 2461\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26517798505287193\nOutput: [0.8263087221589936, 0.9467871235365573]\nHidden Layer: [[1.0, 0.0], [0.8263087221589936, 0.9467871235365573]]\n\nInstance: [1.0, 1.0]\nError: 0.34263839184311673\nOutput: [0.1722085626011332, 0.006174127902090313]\nHidden Layer: [[1.0, 1.0], [0.1722085626011332, 0.006174127902090313]]\nAverage of Error:  0.30390818844799433\nFinal Weight:\n[[[ 0.39717842  0.40365853]\n  [ 1.16256834  2.47555774]\n  [-3.13100344 -7.96094211]]]\n\nEnd of epoch - 2461\n-------------------------------\nInitial weight:\n[[[ 0.39717842  0.40365853]\n  [ 1.16256834  2.47555774]\n  [-3.13100344 -7.96094211]]]\nEpoch - 2462\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20418031572400042\nOutput: [0.598009556825045, 0.5995663441231206]\nHidden Layer: [[0.0, 0.0], [0.598009556825045, 0.5995663441231206]]\n\nInstance: [0.0, 0.1]\nError: 0.1959744188820684\nOutput: [0.5210071453582938, 0.40313109898186494]\nHidden Layer: [[0.0, 0.1], [0.5210071453582938, 0.40313109898186494]]\nAverage of Error:  0.2000773673030344\nFinal Weight:\n[[[ 0.39716025  0.40357241]\n  [ 1.16256834  2.47555774]\n  [-3.12980807 -7.96191211]]]\n\nEnd of epoch - 2462\n-------------------------------\nInitial weight:\n[[[ 0.39716025  0.40357241]\n  [ 1.16256834  2.47555774]\n  [-3.12980807 -7.96191211]]]\nEpoch - 2462\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651811569736754\nOutput: [0.8263144039901699, 0.9468050706950835]\nHidden Layer: [[1.0, 0.0], [0.8263144039901699, 0.9468050706950835]]\n\nInstance: [1.0, 1.0]\nError: 0.3426412297739538\nOutput: [0.17220506174952785, 0.006164394114960325]\nHidden Layer: [[1.0, 1.0], [0.17220506174952785, 0.006164394114960325]]\nAverage of Error:  0.30391119337381456\nFinal Weight:\n[[[ 0.39718     0.40375043]\n  [ 1.16260627  2.47582188]\n  [-3.13106749 -7.96288588]]]\n\nEnd of epoch - 2462\n-------------------------------\nInitial weight:\n[[[ 0.39718     0.40375043]\n  [ 1.16260627  2.47582188]\n  [-3.13106749 -7.96288588]]]\nEpoch - 2463\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20417167022188534\nOutput: [0.5980099360812872, 0.5995884067511494]\nHidden Layer: [[0.0, 0.0], [0.5980099360812872, 0.5995884067511494]]\n\nInstance: [0.0, 0.1]\nError: 0.19596505561416733\nOutput: [0.5210059405317963, 0.40310644031385257]\nHidden Layer: [[0.0, 0.1], [0.5210059405317963, 0.40310644031385257]]\nAverage of Error:  0.20006836291802632\nFinal Weight:\n[[[ 0.39716185  0.40366439]\n  [ 1.16260627  2.47582188]\n  [-3.12987212 -7.96385581]]]\n\nEnd of epoch - 2463\n-------------------------------\nInitial weight:\n[[[ 0.39716185  0.40366439]\n  [ 1.16260627  2.47582188]\n  [-3.12987212 -7.96385581]]]\nEpoch - 2463\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651843237587711\nOutput: [0.8263200772287312, 0.9468230037328916]\nHidden Layer: [[1.0, 0.0], [0.8263200772287312, 0.9468230037328916]]\n\nInstance: [1.0, 1.0]\nError: 0.34264406348332294\nOutput: [0.1722015662403015, 0.006154675591437134]\nHidden Layer: [[1.0, 1.0], [0.1722015662403015, 0.006154675591437134]]\nAverage of Error:  0.303914193621047\nFinal Weight:\n[[[ 0.39718157  0.40384232]\n  [ 1.16264414  2.47608586]\n  [-3.13113145 -7.96482949]]]\n\nEnd of epoch - 2463\n-------------------------------\nInitial weight:\n[[[ 0.39718157  0.40384232]\n  [ 1.16264414  2.47608586]\n  [-3.13113145 -7.96482949]]]\nEpoch - 2464\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20416302539100872\nOutput: [0.5980103147888088, 0.5996104682362825]\nHidden Layer: [[0.0, 0.0], [0.5980103147888088, 0.5996104682362825]]\n\nInstance: [0.0, 0.1]\nError: 0.1959556936219622\nOutput: [0.5210047375260435, 0.4030817854622432]\nHidden Layer: [[0.0, 0.1], [0.5210047375260435, 0.4030817854622432]]\nAverage of Error:  0.20005935950648546\nFinal Weight:\n[[[ 0.39716345  0.40375636]\n  [ 1.16264414  2.47608586]\n  [-3.12993608 -7.96579933]]]\n\nEnd of epoch - 2464\n-------------------------------\nInitial weight:\n[[[ 0.39716345  0.40375636]\n  [ 1.16264414  2.47608586]\n  [-3.12993608 -7.96579933]]]\nEpoch - 2464\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26518748541614057\nOutput: [0.8263257418881765, 0.9468409226672333]\nHidden Layer: [[1.0, 0.0], [0.8263257418881765, 0.9468409226672333]]\n\nInstance: [1.0, 1.0]\nError: 0.3426468929776378\nOutput: [0.17219807606492962, 0.006144972308446781]\nHidden Layer: [[1.0, 1.0], [0.17219807606492962, 0.006144972308446781]]\nAverage of Error:  0.30391718919688915\nFinal Weight:\n[[[ 0.39718315  0.40393421]\n  [ 1.16268195  2.47634968]\n  [-3.13119531 -7.96677293]]]\n\nEnd of epoch - 2464\n-------------------------------\nInitial weight:\n[[[ 0.39718315  0.40393421]\n  [ 1.16268195  2.47634968]\n  [-3.13119531 -7.96677293]]]\nEpoch - 2465\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20415438123203894\nOutput: [0.5980106929483964, 0.5996325285776379]\nHidden Layer: [[0.0, 0.0], [0.5980106929483964, 0.5996325285776379]]\n\nInstance: [0.0, 0.1]\nError: 0.19594633290561397\nOutput: [0.5210035363381769, 0.4030571344247559]\nHidden Layer: [[0.0, 0.1], [0.5210035363381769, 0.4030571344247559]]\nAverage of Error:  0.20005035706882646\nFinal Weight:\n[[[ 0.39716505  0.40384833]\n  [ 1.16268195  2.47634968]\n  [-3.12999994 -7.96774269]]]\n\nEnd of epoch - 2465\n-------------------------------\nInitial weight:\n[[[ 0.39716505  0.40384833]\n  [ 1.16268195  2.47634968]\n  [-3.12999994 -7.96774269]]]\nEpoch - 2465\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.265190641953752\nOutput: [0.826331397981981, 0.9468588275153327]\nHidden Layer: [[1.0, 0.0], [0.826331397981981, 0.9468588275153327]]\n\nInstance: [1.0, 1.0]\nError: 0.3426497182633023\nOutput: [0.17219459121490224, 0.006135284242947104]\nHidden Layer: [[1.0, 1.0], [0.17219459121490224, 0.006135284242947104]]\nAverage of Error:  0.30392018010852717\nFinal Weight:\n[[[ 0.39718472  0.4040261 ]\n  [ 1.16271971  2.47661333]\n  [-3.13125908 -7.9687162 ]]]\n\nEnd of epoch - 2465\n-------------------------------\nInitial weight:\n[[[ 0.39718472  0.4040261 ]\n  [ 1.16271971  2.47661333]\n  [-3.13125908 -7.9687162 ]]]\nEpoch - 2466\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20414573774564337\nOutput: [0.5980110705608347, 0.5996545877743344]\nHidden Layer: [[0.0, 0.0], [0.5980110705608347, 0.5996545877743344]]\n\nInstance: [0.0, 0.1]\nError: 0.19593697346528322\nOutput: [0.5210023369653425, 0.40303248719911294]\nHidden Layer: [[0.0, 0.1], [0.5210023369653425, 0.40303248719911294]]\nAverage of Error:  0.2000413556054633\nFinal Weight:\n[[[ 0.39716665  0.4039403 ]\n  [ 1.16271971  2.47661333]\n  [-3.1300637  -7.96968588]]]\n\nEnd of epoch - 2466\n-------------------------------\nInitial weight:\n[[[ 0.39716665  0.4039403 ]\n  [ 1.16271971  2.47661333]\n  [-3.1300637  -7.96968588]]]\nEpoch - 2466\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2651937933795614\nOutput: [0.8263370455235978, 0.9468767182943871]\nHidden Layer: [[1.0, 0.0], [0.8263370455235978, 0.9468767182943871]]\n\nInstance: [1.0, 1.0]\nError: 0.34265253934670964\nOutput: [0.17219111168172424, 0.006125611371927696]\nHidden Layer: [[1.0, 1.0], [0.17219111168172424, 0.006125611371927696]]\nAverage of Error:  0.30392316636313554\nFinal Weight:\n[[[ 0.39718629  0.40411798]\n  [ 1.16275741  2.47687681]\n  [-3.13132275 -7.9706593 ]]]\n\nEnd of epoch - 2466\n-------------------------------\nInitial weight:\n[[[ 0.39718629  0.40411798]\n  [ 1.16275741  2.47687681]\n  [-3.13132275 -7.9706593 ]]]\nEpoch - 2467\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20413709493248883\nOutput: [0.5980114476269076, 0.5996766458254909]\nHidden Layer: [[0.0, 0.0], [0.5980114476269076, 0.5996766458254909]]\n\nInstance: [0.0, 0.1]\nError: 0.19592761530112962\nOutput: [0.5210011394046914, 0.4030078437830402]\nHidden Layer: [[0.0, 0.1], [0.5210011394046914, 0.4030078437830402]]\nAverage of Error:  0.20003235511680922\nFinal Weight:\n[[[ 0.39716825  0.40403226]\n  [ 1.16275741  2.47687681]\n  [-3.13012737 -7.9716289 ]]]\n\nEnd of epoch - 2467\n-------------------------------\nInitial weight:\n[[[ 0.39716825  0.40403226]\n  [ 1.16275741  2.47687681]\n  [-3.13012737 -7.9716289 ]]]\nEpoch - 2467\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.265196939701512\nOutput: [0.8263426845264572, 0.9468945950215668]\nHidden Layer: [[1.0, 0.0], [0.8263426845264572, 0.9468945950215668]]\n\nInstance: [1.0, 1.0]\nError: 0.3426553562342436\nOutput: [0.1721876374569149, 0.006115953672409862]\nHidden Layer: [[1.0, 1.0], [0.1721876374569149, 0.006115953672409862]]\nAverage of Error:  0.30392614796787776\nFinal Weight:\n[[[ 0.39718785  0.40420986]\n  [ 1.16279505  2.47714014]\n  [-3.13138633 -7.97260223]]]\n\nEnd of epoch - 2467\n-------------------------------\nInitial weight:\n[[[ 0.39718785  0.40420986]\n  [ 1.16279505  2.47714014]\n  [-3.13138633 -7.97260223]]]\nEpoch - 2468\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20412845279324116\nOutput: [0.5980118241473982, 0.5996987027302269]\nHidden Layer: [[0.0, 0.0], [0.5980118241473982, 0.5996987027302269]]\n\nInstance: [0.0, 0.1]\nError: 0.19591825841331245\nOutput: [0.5209999436533792, 0.40298320417426703]\nHidden Layer: [[0.0, 0.1], [0.5209999436533792, 0.40298320417426703]]\nAverage of Error:  0.2000233556032768\nFinal Weight:\n[[[ 0.39716984  0.40412422]\n  [ 1.16279505  2.47714014]\n  [-3.13019094 -7.97357176]]]\n\nEnd of epoch - 2468\n-------------------------------\nInitial weight:\n[[[ 0.39716984  0.40412422]\n  [ 1.16279505  2.47714014]\n  [-3.13019094 -7.97357176]]]\nEpoch - 2468\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.26520008092753417\nOutput: [0.826348315003967, 0.9469124577140153]\nHidden Layer: [[1.0, 0.0], [0.826348315003967, 0.9469124577140153]]\n\nInstance: [1.0, 1.0]\nError: 0.34265816893227713\nOutput: [0.17218416853200835, 0.0061063111214465955]\nHidden Layer: [[1.0, 1.0], [0.17218416853200835, 0.0061063111214465955]]\nAverage of Error:  0.30392912492990565\nFinal Weight:\n[[[ 0.39718942  0.40430174]\n  [ 1.16283264  2.4774033 ]\n  [-3.13144981 -7.97454499]]]\n\nEnd of epoch - 2468\n-------------------------------\nInitial weight:\n[[[ 0.39718942  0.40430174]\n  [ 1.16283264  2.4774033 ]\n  [-3.13144981 -7.97454499]]]\nEpoch - 2469\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20411981132856577\nOutput: [0.5980122001230882, 0.5997207584876619]\nHidden Layer: [[0.0, 0.0], [0.5980122001230882, 0.5997207584876619]]\n\nInstance: [0.0, 0.1]\nError: 0.1959089028019902\nOutput: [0.5209987497085665, 0.40295856837052596]\nHidden Layer: [[0.0, 0.1], [0.5209987497085665, 0.40295856837052596]]\nAverage of Error:  0.20001435706527798\nFinal Weight:\n[[[ 0.39717143  0.40421617]\n  [ 1.16283264  2.4774033 ]\n  [-3.13025442 -7.97551444]]]\n\nEnd of epoch - 2469\n-------------------------------\nInitial weight:\n[[[ 0.39717143  0.40421617]\n  [ 1.16283264  2.4774033 ]\n  [-3.13025442 -7.97551444]]]\nEpoch - 2469\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2652032170655461\nOutput: [0.8263539369695126, 0.9469303063888487]\nHidden Layer: [[1.0, 0.0], [0.8263539369695126, 0.9469303063888487]]\n\nInstance: [1.0, 1.0]\nError: 0.3426609774471735\nOutput: [0.1721807048985531, 0.006096683696122527]\nHidden Layer: [[1.0, 1.0], [0.1721807048985531, 0.006096683696122527]]\nAverage of Error:  0.30393209725635983\nFinal Weight:\n[[[ 0.39719098  0.40439361]\n  [ 1.16287017  2.4776663 ]\n  [-3.1315132  -7.97648758]]]\n\nEnd of epoch - 2469\n-------------------------------\nInitial weight:\n[[[ 0.39719098  0.40439361]\n  [ 1.16287017  2.4776663 ]\n  [-3.1315132  -7.97648758]]]\nEpoch - 2470\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20411117053912686\nOutput: [0.5980125755547583, 0.5997428130969166]\nHidden Layer: [[0.0, 0.0], [0.5980125755547583, 0.5997428130969166]]\n\nInstance: [0.0, 0.1]\nError: 0.19589954846732072\nOutput: [0.5209975575674187, 0.4029339363695531]\nHidden Layer: [[0.0, 0.1], [0.5209975575674187, 0.4029339363695531]]\nAverage of Error:  0.2000053595032238\nFinal Weight:\n[[[ 0.39717302  0.40430813]\n  [ 1.16287017  2.4776663 ]\n  [-3.13031781 -7.97745696]]]\n\nEnd of epoch - 2470\n-------------------------------\nInitial weight:\n[[[ 0.39717302  0.40430813]\n  [ 1.16287017  2.4776663 ]\n  [-3.13031781 -7.97745696]]]\nEpoch - 2470\n-------------------------------\n\nInstance: [1.0, 0.0]\nError: 0.2652063481234532\nOutput: [0.8263595504364568, 0.9469481410631564]\nHidden Layer: [[1.0, 0.0], [0.8263595504364568, 0.9469481410631564]]\n\nInstance: [1.0, 1.0]\nError: 0.34266378178528584\nOutput: [0.17217724654811226, 0.006087071373553899]\nHidden Layer: [[1.0, 1.0], [0.17217724654811226, 0.006087071373553899]]\nAverage of Error:  0.3039350649543695\nFinal Weight:\n[[[ 0.39719254  0.40448548]\n  [ 1.16290765  2.47792913]\n  [-3.13157649 -7.97843001]]]\n\nEnd of epoch - 2470\n-------------------------------\nInitial weight:\n[[[ 0.39719254  0.40448548]\n  [ 1.16290765  2.47792913]\n  [-3.13157649 -7.97843001]]]\nEpoch - 2471\n-------------------------------\n\nInstance: [0.0, 0.0]\nError: 0.20410253042558824\nOutput: [0.5980129504431883, 0.5997648665571113]\nHidden Layer: [[0.0, 0.0], [0.5980129504431883, 0.5997648665571113]]\n\nInstance: [0.0, 0.1]\nError: 0.19589019540946134\nOutput: [0.5209963672271057, 0.40290930816908777]\nHidden Layer: [[0.0, 0.1], [0.5209963672271057, 0.40290930816908777]]\nAverage of Error:  0.1999963629175248\nStopped by error_treshold\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"x = X.tolist()\nnn = ANN()\nactivation = ['relu', 'relu', 'softmax']\nlayer = 4\nneuron_each_layer = [4, 4, 4, 3]\ninp = x\nweight = [\n    [\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n    ],\n    [\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n        [0,0,0,0],\n    ],\n    [\n        [0,0,0],\n        [0,0,0],\n        [0,0,0],\n        [0,0,0],\n        [0,0,0],\n    ]\n]\n\ntarget = []\nfor t in y:\n    if t == 0:\n        target.append([1,0,0])\n    elif t == 1:\n        target.append([0,1,0])\n    elif t == 2:\n        target.append([0,0,1])\n    else:\n        print(\"Classnya lebih dari tiga\")\nlearning_rate = 0.0001\nbatch_size = 10\nmax_iter = 100\nerror_threshold = 0.0001\n\nnn.readInput(activation, layer, neuron_each_layer, inp, weight, target, learning_rate, batch_size, max_iter, error_threshold)\nnn.generateWeight()\nnn.mini_batch()\nnn.saveModel(\"output/iris.json\")","metadata":{"cell_id":"27b17fcd541341d8b7ef9b0d37671aab","source_hash":"5e0a7c9a","execution_start":1683294740013,"execution_millis":332786,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"Instance: [6.6, 2.9, 4.6, 1.3]\nError: 0.7325607879717084\nOutput: [0.009600397179211814, 0.48067650208866325, 0.5097231007321249]\nHidden Layer: [[6.6, 2.9, 4.6, 1.3], [1.2821157830185252, 4.497728636765784, 0, 0], [1.6219369214833967, 0, 3.09727380929196, 0], [0.009600397179211814, 0.48067650208866325, 0.5097231007321249]]\n\nInstance: [5.6, 2.7, 4.2, 1.3]\nError: 0.7437680769121015\nOutput: [0.017444422419811353, 0.4753194964691739, 0.5072360811110147]\nHidden Layer: [[5.6, 2.7, 4.2, 1.3], [0.9300647017275998, 3.8825676689863142, 0, 0], [1.375320629798665, 0, 2.8174288591767356, 0], [0.017444422419811353, 0.4753194964691739, 0.5072360811110147]]\n\nInstance: [5.4, 3.4, 1.5, 0.4]\nError: 0.261237736159364\nOutput: [0.7700978177534475, 0.14765474886233398, 0.08224743338421853]\nHidden Layer: [[5.4, 3.4, 1.5, 0.4], [2.988802468240207, 1.1022957983401982, 0, 0], [0.04899022579602208, 0, 0, 0], [0.7700978177534475, 0.14765474886233398, 0.08224743338421853]]\n\nInstance: [5.1, 3.4, 1.5, 0.2]\nError: 0.2524964125463007\nOutput: [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]\nHidden Layer: [[5.1, 3.4, 1.5, 0.2], [2.884663610942909, 0.9600956908024262, 0, 0], [0, 0, 0, 0], [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]]\n\nInstance: [4.4, 3.2, 1.3, 0.2]\nError: 0.2524964125463007\nOutput: [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]\nHidden Layer: [[4.4, 3.2, 1.3, 0.2], [2.561681777981248, 0.6259713002432924, 0, 0], [0, 0, 0, 0], [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]]\n\nInstance: [6.7, 2.5, 5.8, 1.8]\nError: 8.03456026437491\nOutput: [0.00032406700293335965, 0.34100697788525197, 0.6586689551118147]\nHidden Layer: [[6.7, 2.5, 5.8, 1.8], [0.30791623106190336, 5.795931992924821, 0, 0], [2.241994243211976, 0, 4.981707549014384, 0], [0.00032406700293335965, 0.34100697788525197, 0.6586689551118147]]\n\nInstance: [5.8, 4.0, 1.2, 0.2]\nError: 2.508561703905986\nOutput: [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]\nHidden Layer: [[5.8, 4.0, 1.2, 0.2], [3.697914552470121, 0.6784909089480168, 0, 0], [0, 0, 0, 0], [0.7768589997800069, 0.14175578908809172, 0.08138521113190128]]\nAverage of Error:  1.6151373823158388\nFinal Weight:\n[[list([-0.3188288164125928, -0.5508344498792189, 0.285, 0.435])\n  list([0.49835354409608945, 0.385758847905449, -0.335, -0.18])\n  list([0.4745910086070061, -0.5074009263720938, -0.46, -0.395])\n  list([-0.6006860648267989, 0.8255690957042895, -0.2, -0.495])\n  list([-0.22567948791734593, 0.1315640881383809, 0.475, 0.3])]\n [list([-0.25598297318244057, -0.275, 0.0775775825669809, -0.455])\n  list([-0.05809996888363856, -0.425, -0.7537099853124648, 0.185])\n  list([0.434965397669952, -0.44, 0.8855155768714494, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0894671960660656, -0.6118712366586977, -1.1675959594073675])\n  list([-0.5297630350826136, 0.4814610050223115, -0.1366979699396982])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9428330681696543, 0.3418000495093587, 0.8610330186602954])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3188288164125928, -0.5508344498792189, 0.285, 0.435])\n  list([0.49835354409608945, 0.385758847905449, -0.335, -0.18])\n  list([0.4745910086070061, -0.5074009263720938, -0.46, -0.395])\n  list([-0.6006860648267989, 0.8255690957042895, -0.2, -0.495])\n  list([-0.22567948791734593, 0.1315640881383809, 0.475, 0.3])]\n [list([-0.25598297318244057, -0.275, 0.0775775825669809, -0.455])\n  list([-0.05809996888363856, -0.425, -0.7537099853124648, 0.185])\n  list([0.434965397669952, -0.44, 0.8855155768714494, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0894671960660656, -0.6118712366586977, -1.1675959594073675])\n  list([-0.5297630350826136, 0.4814610050223115, -0.1366979699396982])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9428330681696543, 0.3418000495093587, 0.8610330186602954])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [5.4, 3.9, 1.3, 0.4]\nError: 1.9537273968783886\nOutput: [0.776942476515509, 0.14174474677088625, 0.08131277671360479]\nHidden Layer: [[5.4, 3.9, 1.3, 0.4], [3.3520215758318375, 0.6792651756299691, 0, 0], [0, 0, 0, 0], [0.776942476515509, 0.14174474677088625, 0.08131277671360479]]\n\nInstance: [4.4, 2.9, 1.4, 0.2]\nError: 2.5094521196270585\nOutput: [0.776942476515509, 0.14174474677088625, 0.08131277671360479]\nHidden Layer: [[4.4, 2.9, 1.4, 0.2], [2.364144314229531, 0.8571513460393662, 0, 0], [0, 0, 0, 0], [0.776942476515509, 0.14174474677088625, 0.08131277671360479]]\n\nInstance: [7.0, 3.2, 4.7, 1.4]\nError: 0.6889320812175066\nOutput: [0.011356311227983678, 0.5021119976842457, 0.4865316910877706]\nHidden Layer: [[7.0, 3.2, 4.7, 1.4], [1.5491614320322131, 4.590158994272119, 0, 0], [1.6505711281326338, 0, 2.974616432127892, 0], [0.011356311227983678, 0.5021119976842457, 0.4865316910877706]]\n\nInstance: [7.3, 2.9, 6.3, 1.8]\nError: 1.0722375669469604\nOutput: [0.00019884029897111082, 0.3422418709288919, 0.6575592887721369]\nHidden Layer: [[7.3, 2.9, 6.3, 1.8], [0.504920693789122, 6.231643114937596, 0, 0], [2.425230275845756, 0, 5.215230861648184, 0], [0.00019884029897111082, 0.3422418709288919, 0.6575592887721369]]\n\nInstance: [4.8, 3.4, 1.6, 0.2]\nError: 1.9537273968783886\nOutput: [0.776942476515509, 0.14174474677088625, 0.08131277671360479]\nHidden Layer: [[4.8, 3.4, 1.6, 0.2], [2.68064402320611, 0.9228682411563568, 0, 0], [0, 0, 0, 0], [0.776942476515509, 0.14174474677088625, 0.08131277671360479]]\n\nInstance: [5.0, 2.3, 3.3, 1.0]\nError: 2.592159188064128\nOutput: [0.07485823245961491, 0.4965644011136237, 0.4285773664267615]\nHidden Layer: [[5.0, 2.3, 3.3, 1.0], [1.056554722018186, 3.0668797629547466, 0, 0], [1.016617806043981, 0, 1.997011541041085, 0], [0.07485823245961491, 0.4965644011136237, 0.4285773664267615]]\n\nInstance: [6.1, 2.8, 4.0, 1.3]\nError: 3.503567543498283\nOutput: [0.03008984488169261, 0.5097812045290575, 0.46012895058924985]\nHidden Layer: [[6.1, 2.8, 4.0, 1.3], [1.3538550330734243, 3.8548816258992105, 0, 0], [1.3420982109028774, 0, 2.470721252203294, 0], [0.03008984488169261, 0.5097812045290575, 0.46012895058924985]]\n\nInstance: [6.3, 3.3, 6.0, 2.5]\nError: 7.616912337385957\nOutput: [0.0004920587995236383, 0.35127522626755175, 0.6482327149329247]\nHidden Layer: [[6.3, 3.3, 6.0, 2.5], [0.2186337310417319, 5.48734802946889, 0, 0], [2.118120931638485, 0, 4.771923312164264, 0], [0.0004920587995236383, 0.35127522626755175, 0.6482327149329247]]\n\nInstance: [6.1, 2.8, 4.7, 1.2]\nError: 4.905930826290097\nOutput: [0.007402549387412382, 0.4599423297025301, 0.5326551209100575]\nHidden Layer: [[6.1, 2.8, 4.7, 1.2], [0.9559427364863993, 4.4196235840783755, 0, 0], [1.6108601133733085, 0, 3.270719524300085, 0], [0.007402549387412382, 0.4599423297025301, 0.5326551209100575]]\n\nInstance: [6.4, 3.1, 5.5, 1.8]\nError: 0.5160915167489294\nOutput: [0.0015290566351508468, 0.40162217484886287, 0.5968487685159863]\nHidden Layer: [[6.4, 3.1, 5.5, 1.8], [0.6318695576854823, 5.122524689984842, 0, 0], [1.935426414030919, 0, 4.1374065934146325, 0], [0.0015290566351508468, 0.40162217484886287, 0.5968487685159863]]\nAverage of Error:  2.7312737973535697\nFinal Weight:\n[[list([-0.3186838167798577, -0.550926917566141, 0.285, 0.435])\n  list([0.49912600126612655, 0.3852851724836402, -0.335, -0.18])\n  list([0.4749701184778973, -0.5076895287335091, -0.46, -0.395])\n  list([-0.6002254758997231, 0.8254050738015434, -0.2, -0.495])\n  list([-0.2255760354013963, 0.1315498931878594, 0.475, 0.3])]\n [list([-0.25577057130283287, -0.275, 0.07736882830022415, -0.455])\n  list([-0.05806170998608038, -0.425, -0.7540003795371802, 0.185])\n  list([0.4359771094567832, -0.44, 0.8848790983902536, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0899159247351524, -0.6116110580923101, -1.168304866642842])\n  list([-0.5298067444568308, 0.48205055726231144, -0.1372438128054809])\n  list([-0.275, -0.075, 0.175])\n  list([-0.942946767789919, 0.34289231281429666, 0.8600544549756222])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3186838167798577, -0.550926917566141, 0.285, 0.435])\n  list([0.49912600126612655, 0.3852851724836402, -0.335, -0.18])\n  list([0.4749701184778973, -0.5076895287335091, -0.46, -0.395])\n  list([-0.6002254758997231, 0.8254050738015434, -0.2, -0.495])\n  list([-0.2255760354013963, 0.1315498931878594, 0.475, 0.3])]\n [list([-0.25577057130283287, -0.275, 0.07736882830022415, -0.455])\n  list([-0.05806170998608038, -0.425, -0.7540003795371802, 0.185])\n  list([0.4359771094567832, -0.44, 0.8848790983902536, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0899159247351524, -0.6116110580923101, -1.168304866642842])\n  list([-0.5298067444568308, 0.48205055726231144, -0.1372438128054809])\n  list([-0.275, -0.075, 0.175])\n  list([-0.942946767789919, 0.34289231281429666, 0.8600544549756222])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [6.1, 3.0, 4.9, 1.8]\nError: 0.809841740152873\nOutput: [0.004899357920353625, 0.4449284749637861, 0.5501721671158603]\nHidden Layer: [[6.1, 3.0, 4.9, 1.8], [0.8037534507460489, 4.557518717749246, 0, 0], [1.68453596579914, 0, 3.504191475242042, 0], [0.004899357920353625, 0.4449284749637861, 0.5501721671158603]]\n\nInstance: [5.0, 3.6, 1.4, 0.2]\nError: 2.5104889486412696\nOutput: [0.7770363421897737, 0.14173514485164249, 0.08122851295858383]\nHidden Layer: [[5.0, 3.6, 1.4, 0.2], [3.001407742731314, 0.7296937233711597, 0, 0], [0, 0, 0, 0], [0.7770363421897737, 0.14173514485164249, 0.08122851295858383]]\n\nInstance: [5.8, 2.8, 5.1, 2.4]\nError: 0.934399856978232\nOutput: [0.0017989097848199256, 0.392821543912456, 0.605379546302724]\nHidden Layer: [[5.8, 2.8, 5.1, 2.4], [0.30363091024984945, 4.78748202242388, 0, 0], [1.8138326725561087, 0, 4.084773782294609, 0], [0.0017989097848199256, 0.392821543912456, 0.605379546302724]]\n\nInstance: [6.1, 2.6, 5.6, 1.4]\nError: 0.9954991536934431\nOutput: [0.0007550068651435634, 0.36953894177261304, 0.6297060513622433]\nHidden Layer: [[6.1, 2.6, 5.6, 1.4], [0.2838379843856431, 5.285758123628585, 0, 0], [2.032218857992035, 0, 4.5406117630918015, 0], [0.0007550068651435634, 0.36953894177261304, 0.6297060513622433]]\n\nInstance: [7.7, 2.6, 6.9, 2.3]\nError: 1.2680497862292397\nOutput: [2.7376349079634017e-05, 0.28137983786996845, 0.718592785780952]\nHidden Layer: [[7.7, 2.6, 6.9, 2.3], [0.09912803588054842, 7.09363589941349, 0, 0], [2.831136760391543, 0, 6.27963639060526, 0], [2.7376349079634017e-05, 0.28137983786996845, 0.718592785780952]]\n\nInstance: [5.4, 3.9, 1.7, 0.4]\nError: 0.25253428610470297\nOutput: [0.7768295779224672, 0.14191514018835685, 0.08125528188917586]\nHidden Layer: [[5.4, 3.9, 1.7, 0.4], [3.1183663289309385, 1.0054324345225982, 0, 0], [0.0015172738336796665, 0, 0, 0], [0.7768295779224672, 0.14191514018835685, 0.08125528188917586]]\n\nInstance: [5.5, 2.6, 4.4, 1.2]\nError: 4.517041199298922\nOutput: [0.01092128983045073, 0.4614745728355959, 0.5276041373339534]\nHidden Layer: [[5.5, 2.6, 4.4, 1.2], [0.7497481617859136, 4.037790952938979, 0, 0], [1.4610821966180425, 0, 3.085015247681308, 0], [0.01092128983045073, 0.4614745728355959, 0.5276041373339534]]\n\nInstance: [5.6, 2.8, 4.9, 2.0]\nError: 5.6870035982553295\nOutput: [0.003389734774519625, 0.4148605573881843, 0.5817497078372961]\nHidden Layer: [[5.6, 2.8, 4.9, 2.0], [0.4140812193371274, 4.4927240158917, 0, 0], [1.6789119950648668, 0, 3.740669008259299, 0], [0.003389734774519625, 0.4148605573881843, 0.5817497078372961]]\n\nInstance: [5.8, 2.7, 5.1, 1.9]\nError: 6.214301840208972\nOutput: [0.00200061261023011, 0.3989344868537532, 0.5990649005360167]\nHidden Layer: [[5.8, 2.7, 5.1, 1.9], [0.3689219161027583, 4.772476028703301, 0, 0], [1.8034994953427528, 0, 4.022265848907235, 0], [0.00200061261023011, 0.3989344868537532, 0.5990649005360167]]\n\nInstance: [4.3, 3.0, 1.1, 0.1]\nError: 2.5104889486412696\nOutput: [0.7770363421897737, 0.14173514485164249, 0.08122851295858383]\nHidden Layer: [[4.3, 3.0, 1.1, 0.1], [2.5696627170683435, 0.5038313084134679, 0, 0], [0, 0, 0, 0], [0.7770363421897737, 0.14173514485164249, 0.08122851295858383]]\nAverage of Error:  2.5699649358204253\nFinal Weight:\n[[list([-0.3186043644777012, -0.5509881111586918, 0.285, 0.435])\n  list([0.4994881899491332, 0.38501098668324446, -0.335, -0.18])\n  list([0.475166279290809, -0.5078992640217667, -0.46, -0.395])\n  list([-0.6001317165320542, 0.8254393816011932, -0.2, -0.495])\n  list([-0.22561443493198854, 0.13161310943536672, 0.475, 0.3])]\n [list([-0.2556834404234441, -0.275, 0.0772567444441679, -0.455])\n  list([-0.0581093883435311, -0.425, -0.7542593912177289, 0.185])\n  list([0.43639189828070274, -0.44, 0.8847537776074856, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0904291839491955, -0.6115698119104713, -1.168859372038724])\n  list([-0.5298542583683526, 0.4822762097723271, -0.13742195140397467])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9430687209853441, 0.34317420461060594, 0.8598945163747379])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3186043644777012, -0.5509881111586918, 0.285, 0.435])\n  list([0.4994881899491332, 0.38501098668324446, -0.335, -0.18])\n  list([0.475166279290809, -0.5078992640217667, -0.46, -0.395])\n  list([-0.6001317165320542, 0.8254393816011932, -0.2, -0.495])\n  list([-0.22561443493198854, 0.13161310943536672, 0.475, 0.3])]\n [list([-0.2556834404234441, -0.275, 0.0772567444441679, -0.455])\n  list([-0.0581093883435311, -0.425, -0.7542593912177289, 0.185])\n  list([0.43639189828070274, -0.44, 0.8847537776074856, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0904291839491955, -0.6115698119104713, -1.168859372038724])\n  list([-0.5298542583683526, 0.4822762097723271, -0.13742195140397467])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9430687209853441, 0.34317420461060594, 0.8598945163747379])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [6.5, 3.0, 5.5, 1.8]\nError: 0.9049638820069988\nOutput: [0.0013604826802245834, 0.40455649660786114, 0.5940830207119142]\nHidden Layer: [[6.5, 3.0, 5.5, 1.8], [0.646737284260214, 5.20470570600732, 0, 0], [1.9780264546061779, 0, 4.1943321088654635, 0], [0.0013604826802245834, 0.40455649660786114, 0.5940830207119142]]\n\nInstance: [6.3, 2.9, 5.6, 1.8]\nError: 0.4871890433141215\nOutput: [0.000956063878740973, 0.3846930530819271, 0.6143508830393319]\nHidden Layer: [[6.3, 2.9, 5.6, 1.8], [0.43930984668810125, 5.261037373232966, 0, 0], [2.014662619323076, 0, 4.400625857027277, 0], [0.000956063878740973, 0.3846930530819271, 0.6143508830393319]]\n\nInstance: [7.1, 3.0, 5.9, 2.1]\nError: 0.9740922016482229\nOutput: [0.0004875147360244035, 0.377534923628769, 0.6219775616352066]\nHidden Layer: [[7.1, 3.0, 5.9, 2.1], [0.6386931811372758, 5.805371983488355, 0, 0], [2.2406197895815763, 0, 4.731841207272636, 0], [0.0004875147360244035, 0.377534923628769, 0.6219775616352066]]\n\nInstance: [6.9, 3.1, 5.1, 2.3]\nError: 0.8129287417848979\nOutput: [0.0028288210254779904, 0.44355709784619235, 0.5536140811283297]\nHidden Layer: [[6.9, 3.1, 5.1, 2.3], [1.0212946573157762, 5.043550976355647, 0, 0], [1.8859345363687523, 0, 3.7692364368498326, 0], [0.0028288210254779904, 0.44355709784619235, 0.5536140811283297]]\n\nInstance: [5.5, 2.4, 3.7, 1.0]\nError: 0.6856806911677071\nOutput: [0.03875599050790606, 0.5037472165640342, 0.4574967929280597]\nHidden Layer: [[5.5, 2.4, 3.7, 1.0], [1.1228779644398836, 3.5333529033066946, 0, 0], [1.2209933886481656, 0, 2.3564628233949136, 0], [0.03875599050790606, 0.5037472165640342, 0.4574967929280597]]\n\nInstance: [7.7, 3.8, 6.7, 2.2]\nError: 8.249679648703532\nOutput: [0.00026134226522646765, 0.37051154514034756, 0.629227112594426]\nHidden Layer: [[7.7, 3.8, 6.7, 2.2], [0.8158523018205603, 6.303571980505379, 0, 0], [2.4477356238608925, 0, 5.039001606122243, 0], [0.00026134226522646765, 0.37051154514034756, 0.629227112594426]]\n\nInstance: [6.7, 3.0, 5.2, 2.3]\nError: 6.21692634008767\nOutput: [0.001995368886762937, 0.42335873914942174, 0.5746458919638153]\nHidden Layer: [[6.7, 3.0, 5.2, 2.3], [0.8138672197436626, 5.099882643581295, 0, 0], [1.9225707010856514, 0, 3.9755301850116482, 0], [0.001995368886762937, 0.42335873914942174, 0.5746458919638153]]\n\nInstance: [5.5, 3.5, 1.3, 0.2]\nError: 0.25211457377824004\nOutput: [0.777155691303998, 0.14169001937867268, 0.08115428931732936]\nHidden Layer: [[5.5, 3.5, 1.3, 0.2], [3.2663685392822948, 0.8883187094915943, 0, 0], [0, 0, 0, 0], [0.777155691303998, 0.14169001937867268, 0.08115428931732936]]\n\nInstance: [5.7, 4.4, 1.5, 0.4]\nError: 0.25211457377824004\nOutput: [0.777155691303998, 0.14169001937867268, 0.08115428931732936]\nHidden Layer: [[5.7, 4.4, 1.5, 0.4], [3.6287665983410404, 0.6996220674159646, 0, 0], [0, 0, 0, 0], [0.777155691303998, 0.14169001937867268, 0.08115428931732936]]\n\nInstance: [4.9, 3.0, 1.4, 0.2]\nError: 2.506461797396054\nOutput: [0.7740161130575928, 0.144427594911758, 0.08155629203064925]\nHidden Layer: [[4.9, 3.0, 1.4, 0.2], [2.6690793140142053, 0.9938056876526502, 0, 0], [0.022906743755717995, 0, 0, 0], [0.7740161130575928, 0.144427594911758, 0.08155629203064925]]\nAverage of Error:  2.134215149366568\nFinal Weight:\n[[list([-0.3185979322116073, -0.5510129509281081, 0.285, 0.435])\n  list([0.49933150580751196, 0.38500387676523473, -0.335, -0.18])\n  list([0.475125382981163, -0.5079929894666076, -0.46, -0.395])\n  list([-0.6004769556997758, 0.8257150983991799, -0.2, -0.495])\n  list([-0.2258204848887079, 0.13176919859756592, 0.475, 0.3])]\n [list([-0.2557304075468869, -0.275, 0.07725183494576265, -0.455])\n  list([-0.05827772893343546, -0.425, -0.754446353152884, 0.185])\n  list([0.4360960340235227, -0.44, 0.8852447959164618, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0910049458552742, -0.6117621423992013, -1.1692428034560725])\n  list([-0.5299075387509792, 0.4820642702371713, -0.13715673148619234])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9432030201345055, 0.34253322402028796, 0.8606697961142173])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3185979322116073, -0.5510129509281081, 0.285, 0.435])\n  list([0.49933150580751196, 0.38500387676523473, -0.335, -0.18])\n  list([0.475125382981163, -0.5079929894666076, -0.46, -0.395])\n  list([-0.6004769556997758, 0.8257150983991799, -0.2, -0.495])\n  list([-0.2258204848887079, 0.13176919859756592, 0.475, 0.3])]\n [list([-0.2557304075468869, -0.275, 0.07725183494576265, -0.455])\n  list([-0.05827772893343546, -0.425, -0.754446353152884, 0.185])\n  list([0.4360960340235227, -0.44, 0.8852447959164618, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0910049458552742, -0.6117621423992013, -1.1692428034560725])\n  list([-0.5299075387509792, 0.4820642702371713, -0.13715673148619234])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9432030201345055, 0.34253322402028796, 0.8606697961142173])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [5.7, 2.5, 5.0, 2.0]\nError: 0.9432690094962025\nOutput: [0.0017652800455241404, 0.38935295418990284, 0.6088817657645731]\nHidden Layer: [[5.7, 2.5, 5.0, 2.0], [0.26137936006782353, 4.765640562158242, 0, 0], [1.8073139456971261, 0, 4.098813636812144, 0], [0.0017652800455241404, 0.38935295418990284, 0.6088817657645731]]\n\nInstance: [7.2, 3.0, 5.8, 1.6]\nError: 0.5093109211599931\nOutput: [0.0007662696762495256, 0.39832422011530316, 0.6009095102084474]\nHidden Layer: [[7.2, 3.0, 5.8, 1.6], [0.8578859396653354, 5.697014281853107, 0, 0], [2.1787192822969983, 0, 4.473275161616337, 0], [0.0007662696762495256, 0.39832422011530316, 0.6009095102084474]]\n\nInstance: [7.7, 2.8, 6.7, 2.0]\nError: 1.1613354818024817\nOutput: [6.596856389165314e-05, 0.31306780522142963, 0.6868662262146786]\nHidden Layer: [[7.7, 2.8, 6.7, 2.0], [0.38176916188757754, 6.786966086127335, 0, 0], [2.6817899459337653, 0, 5.797353890819187, 0], [6.596856389165314e-05, 0.31306780522142963, 0.6868662262146786]]\n\nInstance: [6.0, 2.2, 5.0, 1.5]\nError: 0.9401978370175887\nOutput: [0.0014563792916160202, 0.39055056235656876, 0.6079930583518153]\nHidden Layer: [[6.0, 2.2, 5.0, 1.5], [0.38155143936008196, 4.967655022729012, 0, 0], [1.8884082949050787, 0, 4.186982499759446, 0], [0.0014563792916160202, 0.39055056235656876, 0.6079930583518153]]\n\nInstance: [7.2, 3.2, 6.0, 1.8]\nError: 0.9457199214122711\nOutput: [0.0006030724657648304, 0.38839985285573503, 0.6109970746785002]\nHidden Layer: [[7.2, 3.2, 6.0, 1.8], [0.7876515281438718, 5.786912543359135, 0, 0], [2.222016659601834, 0, 4.605845225414692, 0], [0.0006030724657648304, 0.38839985285573503, 0.6109970746785002]]\n\nInstance: [5.2, 4.1, 1.5, 0.1]\nError: 0.25192796179510646\nOutput: [0.777300731401445, 0.1416076533573089, 0.08109161524124626]\nHidden Layer: [[5.2, 4.1, 1.5, 0.1], [3.302642486171689, 0.6199855188965476, 0, 0], [0, 0, 0, 0], [0.777300731401445, 0.1416076533573089, 0.08109161524124626]]\n\nInstance: [4.6, 3.1, 1.5, 0.2]\nError: 0.25192796179510646\nOutput: [0.777300731401445, 0.1416076533573089, 0.08109161524124626]\nHidden Layer: [[4.6, 3.1, 1.5, 0.2], [2.5053361512171475, 0.9101531021637707, 0, 0], [0, 0, 0, 0], [0.777300731401445, 0.1416076533573089, 0.08109161524124626]]\n\nInstance: [6.0, 2.2, 4.0, 1.0]\nError: 4.168687323795838\nOutput: [0.015472557256941931, 0.4870230609192843, 0.4975043818237738]\nHidden Layer: [[6.0, 2.2, 4.0, 1.0], [1.0949386375042116, 4.0760553250310485, 0, 0], [1.4580106170443985, 0, 2.85948613730584, 0], [0.015472557256941931, 0.4870230609192843, 0.4975043818237738]]\n\nInstance: [4.8, 3.0, 1.4, 0.3]\nError: 0.254642935682679\nOutput: [0.7751932423962473, 0.14344392201110825, 0.08136283559264447]\nHidden Layer: [[4.8, 3.0, 1.4, 0.3], [2.595155561161641, 0.968558586483317, 0, 0], [0.015414378404441098, 0, 0, 0], [0.7751932423962473, 0.14344392201110825, 0.08136283559264447]]\n\nInstance: [4.7, 3.2, 1.3, 0.2]\nError: 2.5121757111064533\nOutput: [0.777300731401445, 0.1416076533573089, 0.08109161524124626]\nHidden Layer: [[4.7, 3.2, 1.3, 0.2], [2.7228772312359704, 0.7327111712137978, 0, 0], [0, 0, 0, 0], [0.777300731401445, 0.1416076533573089, 0.08109161524124626]]\nAverage of Error:  1.193919506506372\nFinal Weight:\n[[list([-0.3186415460679605, -0.551016419625883, 0.285, 0.435])\n  list([0.4988241992373933, 0.38516124863709117, -0.335, -0.18])\n  list([0.4749389648638701, -0.5080261735284708, -0.46, -0.395])\n  list([-0.6011377492827891, 0.826158072825165, -0.2, -0.495])\n  list([-0.22612976022420092, 0.13198097759719257, 0.475, 0.3])]\n [list([-0.2558790115993059, -0.275, 0.0773211230572633, -0.455])\n  list([-0.05851980427632444, -0.425, -0.7546070002636438, 0.185])\n  list([0.43526978544450323, -0.44, 0.8861845008121065, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0916679852649627, -0.6121479714217055, -1.1695200138432569])\n  list([-0.5299636412323776, 0.48152573701042584, -0.1365620957780484])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9433437357624842, 0.3411772482871104, 0.8621664874753736])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3186415460679605, -0.551016419625883, 0.285, 0.435])\n  list([0.4988241992373933, 0.38516124863709117, -0.335, -0.18])\n  list([0.4749389648638701, -0.5080261735284708, -0.46, -0.395])\n  list([-0.6011377492827891, 0.826158072825165, -0.2, -0.495])\n  list([-0.22612976022420092, 0.13198097759719257, 0.475, 0.3])]\n [list([-0.2558790115993059, -0.275, 0.0773211230572633, -0.455])\n  list([-0.05851980427632444, -0.425, -0.7546070002636438, 0.185])\n  list([0.43526978544450323, -0.44, 0.8861845008121065, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0916679852649627, -0.6121479714217055, -1.1695200138432569])\n  list([-0.5299636412323776, 0.48152573701042584, -0.1365620957780484])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9433437357624842, 0.3411772482871104, 0.8621664874753736])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [4.8, 3.0, 1.4, 0.1]\nError: 1.955084193730718\nOutput: [0.7774046279993908, 0.14155255835443578, 0.08104281364617345]\nHidden Layer: [[4.8, 3.0, 1.4, 0.1], [2.6363256798448127, 0.9434984529616923, 0, 0], [0.0005200947953842849, 0, 0, 0], [0.7774046279993908, 0.14155255835443578, 0.08104281364617345]]\n\nInstance: [6.7, 3.0, 5.0, 1.7]\nError: 0.6022456866046033\nOutput: [0.0039925404377340445, 0.4484268995849232, 0.5475805599773427]\nHidden Layer: [[6.7, 3.0, 5.0, 1.7], [1.0581881446190984, 4.860643451698268, 0, 0], [1.7978872576329923, 0, 3.586231832400558, 0], [0.0039925404377340445, 0.4484268995849232, 0.5475805599773427]]\n\nInstance: [6.5, 2.8, 4.6, 1.5]\nError: 0.7539266237354515\nOutput: [0.007772375237503148, 0.47051538382359376, 0.5217122409389031]\nHidden Layer: [[6.5, 2.8, 4.6, 1.5], [1.149116563556801, 4.528357012027039, 0, 0], [1.6479318970517884, 0, 3.2231495182805827, 0], [0.007772375237503148, 0.47051538382359376, 0.5217122409389031]]\n\nInstance: [6.0, 3.4, 4.5, 1.6]\nError: 0.6991724097896548\nOutput: [0.02165492712881455, 0.4969964430313677, 0.48134862983981774]\nHidden Layer: [[6.0, 3.4, 4.5, 1.6], [1.2221686417622855, 3.9615429740686134, 0, 0], [1.3969398790441285, 0, 2.6657220934014356, 0], [0.02165492712881455, 0.4969964430313677, 0.48134862983981774]]\n\nInstance: [6.1, 3.0, 4.6, 1.4]\nError: 0.7454051145970167\nOutput: [0.011015092206202065, 0.47454201709622534, 0.5144428906975725]\nHidden Layer: [[6.1, 3.0, 4.6, 1.4], [1.067187652857038, 4.259489180106789, 0, 0], [1.5356963173576552, 0, 3.046707142403919, 0], [0.011015092206202065, 0.47454201709622534, 0.5144428906975725]]\n\nInstance: [6.3, 3.4, 5.6, 2.4]\nError: 6.563512343954016\nOutput: [0.0014109213560958957, 0.39287895401104744, 0.6057101246328566]\nHidden Layer: [[6.3, 3.4, 5.6, 2.4], [0.5296605691430747, 5.091450010845176, 0, 0], [1.929279709383548, 0, 4.1895996360889, 0], [0.0014109213560958957, 0.39287895401104744, 0.6057101246328566]]\n\nInstance: [5.6, 2.5, 3.9, 1.1]\nError: 3.5904973228465598\nOutput: [0.02758460855538491, 0.49279548733094586, 0.47961990411366934]\nHidden Layer: [[5.6, 2.5, 3.9, 1.1], [1.0689414233716183, 3.7030166982957056, 0, 0], [1.2933780292867159, 0, 2.552246446387332, 0], [0.02758460855538491, 0.49279548733094586, 0.47961990411366934]]\n\nInstance: [5.0, 2.0, 3.5, 1.0]\nError: 3.3898621452019952\nOutput: [0.03371332412273105, 0.48101573038671536, 0.4852709454905536]\nHidden Layer: [[5.0, 2.0, 3.5, 1.0], [0.7952454971327836, 3.382271708987901, 0, 0], [1.1697840586430321, 0, 2.474540070033077, 0], [0.03371332412273105, 0.48101573038671536, 0.4852709454905536]]\n\nInstance: [6.3, 2.7, 4.9, 1.8]\nError: 5.77676902065509\nOutput: [0.003098711123201757, 0.4255132263518792, 0.5713880625249189]\nHidden Layer: [[6.3, 2.7, 4.9, 1.8], [0.7536775743708387, 4.789569094779176, 0, 0], [1.7847706365172133, 0, 3.753032646857282, 0], [0.003098711123201757, 0.4255132263518792, 0.5713880625249189]]\n\nInstance: [6.3, 3.3, 4.7, 1.6]\nError: 0.6865100423891549\nOutput: [0.012274563729951837, 0.4843958298786821, 0.5033296063913661]\nHidden Layer: [[6.3, 3.3, 4.7, 1.6], [1.2040944551905577, 4.293125580577621, 0, 0], [1.542325466897065, 0, 2.9732043677396947, 0], [0.012274563729951837, 0.4843958298786821, 0.5033296063913661]]\nAverage of Error:  2.476298490350426\nFinal Weight:\n[[list([-0.31859986722994293, -0.5510603134083923, 0.285, 0.435])\n  list([0.4988262585816564, 0.38508454534449366, -0.335, -0.18])\n  list([0.4749933354855285, -0.5081755131231137, -0.46, -0.395])\n  list([-0.6014488591030192, 0.8264584713593848, -0.2, -0.495])\n  list([-0.22633895477107, 0.13215647588012194, 0.475, 0.3])]\n [list([-0.2558652277657101, -0.275, 0.07726482161128286, -0.455])\n  list([-0.058592554853832524, -0.425, -0.7549243155114179, 0.185])\n  list([0.43513442616417575, -0.44, 0.8866347240806223, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0923410325054614, -0.6122646636971946, -1.1700763688082667])\n  list([-0.5300366772876113, 0.48137867139049195, -0.1363419941028808])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9435183032622217, 0.3405707971223551, 0.8629475061398665])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.31859986722994293, -0.5510603134083923, 0.285, 0.435])\n  list([0.4988262585816564, 0.38508454534449366, -0.335, -0.18])\n  list([0.4749933354855285, -0.5081755131231137, -0.46, -0.395])\n  list([-0.6014488591030192, 0.8264584713593848, -0.2, -0.495])\n  list([-0.22633895477107, 0.13215647588012194, 0.475, 0.3])]\n [list([-0.2558652277657101, -0.275, 0.07726482161128286, -0.455])\n  list([-0.058592554853832524, -0.425, -0.7549243155114179, 0.185])\n  list([0.43513442616417575, -0.44, 0.8866347240806223, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0923410325054614, -0.6122646636971946, -1.1700763688082667])\n  list([-0.5300366772876113, 0.48137867139049195, -0.1363419941028808])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9435183032622217, 0.3405707971223551, 0.8629475061398665])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [5.0, 3.0, 1.6, 0.2]\nError: 1.861773001066699\nOutput: [0.7616813323216114, 0.15539686716476495, 0.08292180051362363]\nHidden Layer: [[5.0, 3.0, 1.6, 0.2], [2.59292546661588, 1.198600723295775, 0, 0], [0.11376108253097272, 0, 0, 0], [0.7616813323216114, 0.15539686716476495, 0.08292180051362363]]\n\nInstance: [5.3, 3.7, 1.5, 0.2]\nError: 2.51390939647802\nOutput: [0.777639682462751, 0.14140916784638566, 0.08095114969086341]\nHidden Layer: [[5.3, 3.7, 1.5, 0.2], [3.1352135649405493, 0.8757573805770047, 0, 0], [0, 0, 0, 0], [0.777639682462751, 0.14140916784638566, 0.08095114969086341]]\n\nInstance: [5.7, 3.0, 4.2, 1.2]\nError: 0.7003049689830495\nOutput: [0.028168809827840594, 0.49643388376669395, 0.47539730640546546]\nHidden Layer: [[5.7, 3.0, 4.2, 1.2], [1.15199785918412, 3.7491084064514433, 0, 0], [1.308002409547083, 0, 2.531683323798509, 0], [0.028168809827840594, 0.49643388376669395, 0.47539730640546546]]\n\nInstance: [6.4, 3.2, 5.3, 2.3]\nError: 0.8921393089718574\nOutput: [0.0020894967290178775, 0.40977817225874696, 0.5881323310122352]\nHidden Layer: [[6.4, 3.2, 5.3, 2.3], [0.6856083120268877, 4.971508927531423, 0, 0], [1.8672379139550734, 0, 3.96759488217162, 0], [0.0020894967290178775, 0.40977817225874696, 0.5881323310122352]]\n\nInstance: [5.2, 3.5, 1.5, 0.2]\nError: 1.9560976913669483\nOutput: [0.777639682462751, 0.14140916784638566, 0.08095114969086341]\nHidden Layer: [[5.2, 3.5, 1.5, 0.2], [2.990332271985278, 0.9388840286671782, 0, 0], [0, 0, 0, 0], [0.777639682462751, 0.14140916784638566, 0.08095114969086341]]\n\nInstance: [5.8, 2.7, 4.1, 1.0]\nError: 3.6879670429121805\nOutput: [0.025022820689387038, 0.4952798154300726, 0.47969736388054035]\nHidden Layer: [[5.8, 2.7, 4.1, 1.0], [1.1647951612611434, 3.8309923726108632, 0, 0], [1.3428831155499799, 0, 2.5946234970300037, 0], [0.025022820689387038, 0.4952798154300726, 0.47969736388054035]]\n\nInstance: [6.9, 3.1, 5.4, 2.1]\nError: 6.445692515575486\nOutput: [0.0015873449272743574, 0.4121032408121265, 0.586309414260599]\nHidden Layer: [[6.9, 3.1, 5.4, 2.1], [0.8726450128130743, 5.271083303475896, 0, 0], [1.9866340799746682, 0, 4.092009373012246, 0], [0.0015873449272743574, 0.4121032408121265, 0.586309414260599]]\n\nInstance: [5.2, 2.7, 3.9, 1.4]\nError: 3.4448578009564867\nOutput: [0.031909299191835445, 0.48457511771374745, 0.48351558309441706]\nHidden Layer: [[5.2, 2.7, 3.9, 1.4], [0.8952535960243249, 3.4875125414843393, 0, 0], [1.209216345280298, 0, 2.493565833370161, 0], [0.031909299191835445, 0.48457511771374745, 0.48351558309441706]]\n\nInstance: [4.6, 3.2, 1.4, 0.2]\nError: 0.25149199516429227\nOutput: [0.777639682462751, 0.14140916784638566, 0.08095114969086341]\nHidden Layer: [[4.6, 3.2, 1.4, 0.2], [2.6086834021009273, 0.7776401082614774, 0, 0], [0, 0, 0, 0], [0.777639682462751, 0.14140916784638566, 0.08095114969086341]]\n\nInstance: [5.8, 2.7, 5.1, 1.9]\nError: 0.4990332143329086\nOutput: [0.0019397869678833704, 0.39094288462527454, 0.6071173284068422]\nHidden Layer: [[5.8, 2.7, 5.1, 1.9], [0.3596412428641614, 4.776391672262357, 0, 0], [1.8014349224292996, 0, 4.040677614949697, 0], [0.0019397869678833704, 0.39094288462527454, 0.6071173284068422]]\nAverage of Error:  2.2253266935807927\nFinal Weight:\n[[list([-0.3185581739267189, -0.5511028885879924, 0.285, 0.435])\n  list([0.49879137393618983, 0.3850404969798722, -0.335, -0.18])\n  list([0.47503860722855595, -0.5083173562468194, -0.46, -0.395])\n  list([-0.6018173953310861, 0.8268162236322307, -0.2, -0.495])\n  list([-0.22659012642313525, 0.13236535944261435, 0.475, 0.3])]\n [list([-0.2558477777282429, -0.275, 0.07720823879281508, -0.455])\n  list([-0.05865878425380617, -0.425, -0.7552701706989002, 0.185])\n  list([0.43496150522165744, -0.44, 0.887170620022005, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.093095547952156, -0.6124082297212148, -1.1706873182309412])\n  list([-0.5301189604340542, 0.4811969975842253, -0.1360780371501713])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9437167138623067, 0.33986212959755835, 0.8638545842647483])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3185581739267189, -0.5511028885879924, 0.285, 0.435])\n  list([0.49879137393618983, 0.3850404969798722, -0.335, -0.18])\n  list([0.47503860722855595, -0.5083173562468194, -0.46, -0.395])\n  list([-0.6018173953310861, 0.8268162236322307, -0.2, -0.495])\n  list([-0.22659012642313525, 0.13236535944261435, 0.475, 0.3])]\n [list([-0.2558477777282429, -0.275, 0.07720823879281508, -0.455])\n  list([-0.05865878425380617, -0.425, -0.7552701706989002, 0.185])\n  list([0.43496150522165744, -0.44, 0.887170620022005, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.093095547952156, -0.6124082297212148, -1.1706873182309412])\n  list([-0.5301189604340542, 0.4811969975842253, -0.1360780371501713])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9437167138623067, 0.33986212959755835, 0.8638545842647483])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [6.9, 3.1, 4.9, 1.5]\nError: 0.7552308800553439\nOutput: [0.006150722603976003, 0.46990211117993164, 0.5239471662160925]\nHidden Layer: [[6.9, 3.1, 4.9, 1.5], [1.3069315618844897, 4.779840271169838, 0, 0], [1.7465357248158129, 0, 3.3306556719364298, 0], [0.006150722603976003, 0.46990211117993164, 0.5239471662160925]]\n\nInstance: [5.7, 2.9, 4.2, 1.3]\nError: 0.7162343150240056\nOutput: [0.02323374147433078, 0.48817759140552386, 0.4885886671201453]\nHidden Layer: [[5.7, 2.9, 4.2, 1.3], [1.079964393731738, 3.814210717612271, 0, 0], [1.339837658863266, 0, 2.6453990340289657, 0], [0.02323374147433078, 0.48817759140552386, 0.4885886671201453]]\n\nInstance: [5.5, 2.4, 3.8, 1.1]\nError: 0.7149208283907164\nOutput: [0.0293498119633853, 0.489230843456275, 0.4814193445803397]\nHidden Layer: [[5.5, 2.4, 3.8, 1.1], [1.028731798747283, 3.6341617349982904, 0, 0], [1.2645285241078168, 0, 2.524359317248247, 0], [0.0293498119633853, 0.489230843456275, 0.4814193445803397]]\n\nInstance: [6.7, 3.3, 5.7, 2.5]\nError: 0.9662623093301747\nOutput: [0.000905871375443366, 0.3805025844980368, 0.61859154412652]\nHidden Layer: [[6.7, 3.3, 5.7, 2.5], [0.5941369658549585, 5.394987038872899, 0, 0], [2.0559125532539486, 0, 4.414748307460565, 0], [0.000905871375443366, 0.3805025844980368, 0.61859154412652]]\n\nInstance: [6.8, 3.0, 5.5, 2.1]\nError: 0.9370574661415261\nOutput: [0.001099914382507336, 0.3917789637767114, 0.6071211218407813]\nHidden Layer: [[6.8, 3.0, 5.5, 2.1], [0.7125040507154812, 5.36767690694144, 0, 0], [2.0370904278676534, 0, 4.301120432394311, 0], [0.001099914382507336, 0.3917789637767114, 0.6071211218407813]]\n\nInstance: [6.6, 3.0, 4.4, 1.4]\nError: 4.123335792517653\nOutput: [0.01619041639232081, 0.5000392112385127, 0.4837703723691665]\nHidden Layer: [[6.6, 3.0, 4.4, 1.4], [1.4333579992886327, 4.288515209940182, 0, 0], [1.5254122155145717, 0, 2.799280395773885, 0], [0.01619041639232081, 0.5000392112385127, 0.4837703723691665]]\n\nInstance: [6.0, 2.7, 5.1, 1.6]\nError: 6.109693885103521\nOutput: [0.0022212306605309306, 0.40114885690095875, 0.5966299124385103]\nHidden Layer: [[6.0, 2.7, 5.1, 1.6], [0.5249813907419656, 4.8152305470573875, 0, 0], [1.8077973788723474, 0, 3.952636524175185, 0], [0.0022212306605309306, 0.40114885690095875, 0.5966299124385103]]\n\nInstance: [5.9, 3.0, 5.1, 1.8]\nError: 5.772983849771665\nOutput: [0.003110462500776894, 0.41266650513699293, 0.5842230323622303]\nHidden Layer: [[5.9, 3.0, 5.1, 1.8], [0.5722958102322862, 4.650704362373878, 0, 0], [1.7334594156090546, 0, 3.7709385572146874, 0], [0.003110462500776894, 0.41266650513699293, 0.5842230323622303]]\n\nInstance: [4.6, 3.4, 1.4, 0.3]\nError: 0.2512545665177513\nOutput: [0.7778243383204824, 0.14131577633336412, 0.08085988534615343]\nHidden Layer: [[4.6, 3.4, 1.4, 0.3], [2.6804920193663833, 0.6890567071981408, 0, 0], [0, 0, 0, 0], [0.7778243383204824, 0.14131577633336412, 0.08085988534615343]]\n\nInstance: [5.0, 3.5, 1.3, 0.3]\nError: 2.5150374327008485\nOutput: [0.7778243383204824, 0.14131577633336412, 0.08085988534615343]\nHidden Layer: [[5.0, 3.5, 1.3, 0.3], [2.987694169196824, 0.709559548002185, 0, 0], [0, 0, 0, 0], [0.7778243383204824, 0.14131577633336412, 0.08085988534615343]]\nAverage of Error:  2.28620113255532\nFinal Weight:\n[[list([-0.3184747353769173, -0.551160246864245, 0.285, 0.435])\n  list([0.4990003394998694, 0.3849118894531327, -0.335, -0.18])\n  list([0.47518989532703976, -0.5084946369008883, -0.46, -0.395])\n  list([-0.6020364032828918, 0.8271280814224253, -0.2, -0.495])\n  list([-0.22681506438669669, 0.13257144979171226, 0.475, 0.3])]\n [list([-0.25573672448352724, -0.275, 0.07708913863288043, -0.455])\n  list([-0.05859469253070269, -0.425, -0.7557090562019765, 0.185])\n  list([0.43512852173673233, -0.44, 0.8874890736416715, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0938862723140512, -0.612433403567261, -1.1714528687467902])\n  list([-0.5302129628849727, 0.48119602517509125, -0.1359830622901188])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9439381843205552, 0.3394789053305192, 0.8644592789900358])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3184747353769173, -0.551160246864245, 0.285, 0.435])\n  list([0.4990003394998694, 0.3849118894531327, -0.335, -0.18])\n  list([0.47518989532703976, -0.5084946369008883, -0.46, -0.395])\n  list([-0.6020364032828918, 0.8271280814224253, -0.2, -0.495])\n  list([-0.22681506438669669, 0.13257144979171226, 0.475, 0.3])]\n [list([-0.25573672448352724, -0.275, 0.07708913863288043, -0.455])\n  list([-0.05859469253070269, -0.425, -0.7557090562019765, 0.185])\n  list([0.43512852173673233, -0.44, 0.8874890736416715, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0938862723140512, -0.612433403567261, -1.1714528687467902])\n  list([-0.5302129628849727, 0.48119602517509125, -0.1359830622901188])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9439381843205552, 0.3394789053305192, 0.8644592789900358])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [4.4, 3.0, 1.3, 0.2]\nError: 1.9573332187520036\nOutput: [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]\nHidden Layer: [[4.4, 3.0, 1.3, 0.2], [2.474686107258529, 0.7187489518343696, 0, 0], [0, 0, 0, 0], [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]]\n\nInstance: [6.3, 2.8, 5.1, 1.5]\nError: 0.5438594264044619\nOutput: [0.002663732651728797, 0.41683275447687973, 0.5805035128713916]\nHidden Layer: [[6.3, 2.8, 5.1, 1.5], [0.7451508570651778, 4.867210063309941, 0, 0], [1.8184633099879512, 0, 3.8335676380184225, 0], [0.002663732651728797, 0.41683275447687973, 0.5805035128713916]]\n\nInstance: [5.9, 3.0, 4.2, 1.5]\nError: 0.70560402224643\nOutput: [0.02400949087627885, 0.49381021180299, 0.48218029732073125]\nHidden Layer: [[5.9, 3.0, 4.2, 1.5], [1.182421463285241, 3.867131106868328, 0, 0], [1.3576786953273197, 0, 2.6155591342660953, 0], [0.02400949087627885, 0.49381021180299, 0.48218029732073125]]\n\nInstance: [5.0, 3.2, 1.2, 0.2]\nError: 1.9573332187520036\nOutput: [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]\nHidden Layer: [[5.0, 3.2, 1.2, 0.2], [2.9293279303521476, 0.7652843499838289, 0, 0], [0, 0, 0, 0], [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]]\n\nInstance: [5.6, 2.9, 3.6, 1.3]\nError: 0.6723455800026794\nOutput: [0.07784901642146193, 0.5105097309245455, 0.41164125265399265]\nHidden Layer: [[5.6, 2.9, 3.6, 1.3], [1.3917872267496503, 3.2797158649106795, 0, 0], [1.08980984691201, 0, 1.9360149218294085, 0], [0.07784901642146193, 0.5105097309245455, 0.41164125265399265]]\n\nInstance: [5.8, 2.7, 3.9, 1.2]\nError: 3.38066101848763\nOutput: [0.03402495617436437, 0.5019129894651287, 0.46406205436050685]\nHidden Layer: [[5.8, 2.7, 3.9, 1.2], [1.2386199010380186, 3.6932784496290396, 0, 0], [1.2787375154019553, 0, 2.418797132188479, 0], [0.03402495617436437, 0.5019129894651287, 0.46406205436050685]]\n\nInstance: [5.1, 3.7, 1.5, 0.4]\nError: 0.25101354287069144\nOutput: [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]\nHidden Layer: [[5.1, 3.7, 1.5, 0.4], [2.9908489781034473, 0.824180934863768, 0, 0], [0, 0, 0, 0], [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]]\n\nInstance: [5.6, 3.0, 4.5, 1.5]\nError: 4.341946537227753\nOutput: [0.013011176797701328, 0.46356379794220604, 0.5234250252600926]\nHidden Layer: [[5.6, 3.0, 4.5, 1.5], [0.8521104404504124, 3.9997959644591154, 0, 0], [1.4347594315197216, 0, 2.9829167771537652, 0], [0.013011176797701328, 0.46356379794220604, 0.5234250252600926]]\n\nInstance: [5.0, 3.4, 1.5, 0.2]\nError: 0.25101354287069144\nOutput: [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]\nHidden Layer: [[5.0, 3.4, 1.5, 0.2], [2.843754988432688, 0.9117238470303791, 0, 0], [0, 0, 0, 0], [0.7780118349739322, 0.14123456083509747, 0.08075360419097018]]\n\nInstance: [6.5, 3.0, 5.2, 2.0]\nError: 0.5363929049304708\nOutput: [0.0022164586057093778, 0.41292946500193184, 0.5848540763923588]\nHidden Layer: [[6.5, 3.0, 5.2, 2.0], [0.7663777315089225, 4.99149204685849, 0, 0], [1.871298163586521, 0, 3.9278251992162727, 0], [0.0022164586057093778, 0.41292946500193184, 0.5848540763923588]]\nAverage of Error:  1.4597503012544817\nFinal Weight:\n[[list([-0.3183689743944721, -0.5512144369094591, 0.285, 0.435])\n  list([0.49931626141456675, 0.38481305281422584, -0.335, -0.18])\n  list([0.4754061985058105, -0.5086630907202939, -0.46, -0.395])\n  list([-0.6021950648611404, 0.8274674466201556, -0.2, -0.495])\n  list([-0.22702043917199238, 0.13278790196502363, 0.475, 0.3])]\n [list([-0.25554559595217524, -0.275, 0.07693436994377482, -0.455])\n  list([-0.05841660023272749, -0.425, -0.7562046539874404, 0.185])\n  list([0.435530614523469, -0.44, 0.8877251862407383, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.094750414458804, -0.6123950271326025, -1.1723553873262016])\n  list([-0.5303258259609387, 0.48130470922926555, -0.13597888326832705])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9441950091073882, 0.3392813485087503, 0.8649136605986377])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.3183689743944721, -0.5512144369094591, 0.285, 0.435])\n  list([0.49931626141456675, 0.38481305281422584, -0.335, -0.18])\n  list([0.4754061985058105, -0.5086630907202939, -0.46, -0.395])\n  list([-0.6021950648611404, 0.8274674466201556, -0.2, -0.495])\n  list([-0.22702043917199238, 0.13278790196502363, 0.475, 0.3])]\n [list([-0.25554559595217524, -0.275, 0.07693436994377482, -0.455])\n  list([-0.05841660023272749, -0.425, -0.7562046539874404, 0.185])\n  list([0.435530614523469, -0.44, 0.8877251862407383, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.094750414458804, -0.6123950271326025, -1.1723553873262016])\n  list([-0.5303258259609387, 0.48130470922926555, -0.13597888326832705])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9441950091073882, 0.3392813485087503, 0.8649136605986377])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [6.0, 3.0, 4.8, 1.8]\nError: 0.8183997895709795\nOutput: [0.005845325896772459, 0.44113700203453243, 0.553017672068695]\nHidden Layer: [[6.0, 3.0, 4.8, 1.8], [0.8045740877672998, 4.442536575128804, 0, 0], [1.632314605813946, 0, 3.412263308833952, 0], [0.005845325896772459, 0.44113700203453243, 0.553017672068695]]\n\nInstance: [5.7, 2.6, 3.5, 1.0]\nError: 0.8826540533030137\nOutput: [0.07287966452485731, 0.5134368201766969, 0.4136835152984457]\nHidden Layer: [[5.7, 2.6, 3.5, 1.0], [1.429086665597682, 3.348619893394432, 0, 0], [1.1193984995812736, 0, 1.9689066009804281, 0], [0.07287966452485731, 0.5134368201766969, 0.4136835152984457]]\n\nInstance: [5.0, 3.5, 1.6, 0.6]\nError: 1.9427650299507733\nOutput: [0.7757411060786146, 0.14330715288297788, 0.08095174103840758]\nHidden Layer: [[5.0, 3.5, 1.6, 0.6], [2.742409660167678, 0.9961506654119043, 0, 0], [0.018106266720248676, 0, 0, 0], [0.7757411060786146, 0.14330715288297788, 0.08095174103840758]]\n\nInstance: [6.2, 3.4, 5.4, 2.3]\nError: 0.9028033905591638\nOutput: [0.0022288823064735637, 0.40543148231817133, 0.592339635375355]\nHidden Layer: [[6.2, 3.4, 5.4, 2.3], [0.6197725609498567, 4.878908368358137, 0, 0], [1.8331633579943178, 0, 3.9393893148920016, 0], [0.0022288823064735637, 0.40543148231817133, 0.592339635375355]]\n\nInstance: [5.6, 3.0, 4.1, 1.3]\nError: 0.7002723930165264\nOutput: [0.03286135926033281, 0.49645005584368157, 0.47068858489598553]\nHidden Layer: [[5.6, 3.0, 4.1, 1.3], [1.1398943481902675, 3.642990190386492, 0, 0], [1.2644994079240466, 0, 2.448915104022346, 0], [0.03286135926033281, 0.49645005584368157, 0.47068858489598553]]\n\nInstance: [6.3, 2.5, 5.0, 1.9]\nError: 6.353895302980464\nOutput: [0.0017399562617786397, 0.3962978434643356, 0.6019622002738857]\nHidden Layer: [[6.3, 2.5, 5.0, 1.9], [0.5735248100493375, 4.991084315853752, 0, 0], [1.884721053717854, 0, 4.0739434932417025, 0], [0.0017399562617786397, 0.3962978434643356, 0.6019622002738857]]\n\nInstance: [6.3, 2.3, 4.4, 1.3]\nError: 5.057240647133496\nOutput: [0.006363093330610447, 0.4525339691042938, 0.5411029375650959]\nHidden Layer: [[6.3, 2.3, 4.4, 1.3], [0.9759728727680546, 4.516663724846703, 0, 0], [1.6545867145796915, 0, 3.348455287717406, 0], [0.006363093330610447, 0.4525339691042938, 0.5411029375650959]]\n\nInstance: [6.7, 3.1, 4.4, 1.4]\nError: 3.9891021718730864\nOutput: [0.018516331141994583, 0.5079364814224776, 0.4735471874355278]\nHidden Layer: [[6.7, 3.1, 4.4, 1.4], [1.5333222922213308, 4.276937263592661, 0, 0], [1.5176200433660374, 0, 2.7141738453660627, 0], [0.018516331141994583, 0.5079364814224776, 0.4735471874355278]]\n\nInstance: [6.8, 3.2, 5.9, 2.3]\nError: 7.4955722534401215\nOutput: [0.0005555387171685916, 0.3629650813366537, 0.6364793799461775]\nHidden Layer: [[6.8, 3.2, 5.9, 2.3], [0.5231835456668642, 5.625262541500808, 0, 0], [2.16386585156796, 0, 4.674987775127695, 0], [0.0005555387171685916, 0.3629650813366537, 0.6364793799461775]]\n\nInstance: [7.7, 3.0, 6.1, 2.3]\nError: 0.4382941752293202\nOutput: [0.00026191687612515463, 0.35460211120653135, 0.6451359719173435]\nHidden Layer: [[7.7, 3.0, 6.1, 2.3], [0.7570479282665851, 6.2388203965017, 0, 0], [2.4174275190551993, 0, 5.042809201704022, 0], [0.00026191687612515463, 0.35460211120653135, 0.6451359719173435]]\nAverage of Error:  2.8580999207056945\nFinal Weight:\n[[list([-0.31827895126030814, -0.5512528533866653, 0.285, 0.435])\n  list([0.4995048160630168, 0.3848322215255111, -0.335, -0.18])\n  list([0.47555944666209254, -0.5087824206411773, -0.46, -0.395])\n  list([-0.6025100756137965, 0.827937189843784, -0.2, -0.495])\n  list([-0.22730658559273556, 0.13306163392622666, 0.475, 0.3])]\n [list([-0.25536229332313, -0.275, 0.07680116387312275, -0.455])\n  list([-0.058201614652505465, -0.425, -0.756734359676425, 0.185])\n  list([0.4358043275458795, -0.44, 0.8881673406032912, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0956228572861173, -0.6123640604979231, -1.1732587967881944])\n  list([-0.5304563335403839, 0.48131124902113326, -0.1358549154807495])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9444853602592274, 0.33879958056648896, 0.8656857796927382])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.31827895126030814, -0.5512528533866653, 0.285, 0.435])\n  list([0.4995048160630168, 0.3848322215255111, -0.335, -0.18])\n  list([0.47555944666209254, -0.5087824206411773, -0.46, -0.395])\n  list([-0.6025100756137965, 0.827937189843784, -0.2, -0.495])\n  list([-0.22730658559273556, 0.13306163392622666, 0.475, 0.3])]\n [list([-0.25536229332313, -0.275, 0.07680116387312275, -0.455])\n  list([-0.058201614652505465, -0.425, -0.756734359676425, 0.185])\n  list([0.4358043275458795, -0.44, 0.8881673406032912, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0956228572861173, -0.6123640604979231, -1.1732587967881944])\n  list([-0.5304563335403839, 0.48131124902113326, -0.1358549154807495])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9444853602592274, 0.33879958056648896, 0.8656857796927382])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [6.4, 2.8, 5.6, 2.2]\nError: 1.0336689494226388\nOutput: [0.0006227754017438923, 0.3556995200205539, 0.6436777045777023]\nHidden Layer: [[6.4, 2.8, 5.6, 2.2], [0.33598741045558045, 5.416266444344198, 0, 0], [2.085515052472176, 0, 4.633098909834709, 0], [0.0006227754017438923, 0.3556995200205539, 0.6436777045777023]]\n\nInstance: [4.7, 3.2, 1.6, 0.2]\nError: 2.514109992030223\nOutput: [0.7751239406847572, 0.14394114643638245, 0.08093491287886032]\nHidden Layer: [[4.7, 3.2, 1.6, 0.2], [2.5417064754539456, 0.9806666722667694, 0, 0], [0.024085065486596502, 0, 0, 0], [0.7751239406847572, 0.14394114643638245, 0.08093491287886032]]\n\nInstance: [4.9, 3.6, 1.4, 0.1]\nError: 1.9584794843907607\nOutput: [0.7784172662739144, 0.14107276126136917, 0.08050997246471647]\nHidden Layer: [[4.9, 3.6, 1.4, 0.1], [2.9750638910134186, 0.675226546954021, 0, 0], [0, 0, 0, 0], [0.7784172662739144, 0.14107276126136917, 0.08050997246471647]]\n\nInstance: [6.5, 3.0, 5.8, 2.2]\nError: 1.04097532515325\nOutput: [0.0005393949617678976, 0.35311011677579096, 0.6463504882624412]\nHidden Layer: [[6.5, 3.0, 5.8, 2.2], [0.36054776627153995, 5.5185806203372705, 0, 0], [2.128674560774319, 0, 4.705385354300678, 0], [0.0005393949617678976, 0.35311011677579096, 0.6463504882624412]]\n\nInstance: [5.7, 2.8, 4.1, 1.3]\nError: 0.7147611143100866\nOutput: [0.024654987186279877, 0.48930898675077944, 0.4860360260629407]\nHidden Layer: [[5.7, 2.8, 4.1, 1.3], [1.0946750796656246, 3.78522263397706, 0, 0], [1.330542254132286, 0, 2.610334038819407, 0], [0.024654987186279877, 0.48930898675077944, 0.4860360260629407]]\n\nInstance: [6.4, 2.7, 5.3, 1.9]\nError: 6.723371420342678\nOutput: [0.0012024773158230816, 0.38349142923666674, 0.6153060934475102]\nHidden Layer: [[6.4, 2.7, 5.3, 1.9], [0.5373764641513306, 5.178845039277312, 0, 0], [1.9703246085935713, 0, 4.269830955299861, 0], [0.0012024773158230816, 0.38349142923666674, 0.6153060934475102]]\n\nInstance: [6.7, 3.3, 5.7, 2.1]\nError: 6.822984474187807\nOutput: [0.0010884675665595906, 0.38839730123866206, 0.6105142311947783]\nHidden Layer: [[6.7, 3.3, 5.7, 2.1], [0.6860982296034246, 5.346812456073019, 0, 0], [2.03486968883656, 0, 4.306471259233971, 0], [0.0010884675665595906, 0.38839730123866206, 0.6105142311947783]]\n\nInstance: [7.2, 3.6, 6.1, 2.5]\nError: 7.469301460641169\nOutput: [0.0005703265533074417, 0.3738701505238304, 0.6255595229228621]\nHidden Layer: [[7.2, 3.6, 6.1, 2.5], [0.7465918071509481, 5.770993370151425, 0, 0], [2.2162087429649233, 0, 4.637437324955701, 0], [0.0005703265533074417, 0.3738701505238304, 0.6255595229228621]]\n\nInstance: [6.7, 3.1, 4.7, 1.5]\nError: 4.672217411434249\nOutput: [0.009351510373689888, 0.4808856182733737, 0.5097628713529364]\nHidden Layer: [[6.7, 3.1, 4.7, 1.5], [1.329880367240444, 4.540794770001734, 0, 0], [1.6461345332732615, 0, 3.10342061082095, 0], [0.009351510373689888, 0.4808856182733737, 0.5097628713529364]]\n\nInstance: [5.1, 3.8, 1.5, 0.3]\nError: 2.5193742206810317\nOutput: [0.7784172662739144, 0.14107276126136917, 0.08050997246471647]\nHidden Layer: [[5.1, 3.8, 1.5, 0.3], [3.0643644188785126, 0.7598425529005115, 0, 0], [0, 0, 0, 0], [0.7784172662739144, 0.14107276126136917, 0.08050997246471647]]\nAverage of Error:  3.546924385259389\nFinal Weight:\n[[list([-0.31822246275919946, -0.551276510883696, 0.285, 0.435])\n  list([0.4994535658461211, 0.3849712074408657, -0.335, -0.18])\n  list([0.4756047869551323, -0.5088551325953242, -0.46, -0.395])\n  list([-0.6030653946824241, 0.8285441764691549, -0.2, -0.495])\n  list([-0.22769489394288717, 0.1333957434420451, 0.475, 0.3])]\n [list([-0.2552462582918856, -0.275, 0.07671759171008474, -0.455])\n  list([-0.05801494304167414, -0.425, -0.7572714501578665, 0.185])\n  list([0.43570852486414985, -0.44, 0.8889435216292866, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0965583012721716, -0.6124581788424216, -1.1741001224297503])\n  list([-0.5305919488516875, 0.4810840461362541, -0.13549209728456676])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9447868383656972, 0.3377768855637414, 0.8670099528019556])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\nInitial weight:\n[[list([-0.31822246275919946, -0.551276510883696, 0.285, 0.435])\n  list([0.4994535658461211, 0.3849712074408657, -0.335, -0.18])\n  list([0.4756047869551323, -0.5088551325953242, -0.46, -0.395])\n  list([-0.6030653946824241, 0.8285441764691549, -0.2, -0.495])\n  list([-0.22769489394288717, 0.1333957434420451, 0.475, 0.3])]\n [list([-0.2552462582918856, -0.275, 0.07671759171008474, -0.455])\n  list([-0.05801494304167414, -0.425, -0.7572714501578665, 0.185])\n  list([0.43570852486414985, -0.44, 0.8889435216292866, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.0965583012721716, -0.6124581788424216, -1.1741001224297503])\n  list([-0.5305919488516875, 0.4810840461362541, -0.13549209728456676])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9447868383656972, 0.3377768855637414, 0.8670099528019556])\n  list([0.345, -0.075, -0.315])]]\nEpoch - 100\n-------------------------------\n\nInstance: [4.9, 2.5, 4.5, 1.7]\nError: 0.8997153793832562\nOutput: [0.0057443621103518165, 0.4066853943173458, 0.5875702435723024]\nHidden Layer: [[4.9, 2.5, 4.5, 1.7], [0.21723638150080782, 4.018166132050909, 0, 0], [1.482900023463754, 0, 3.484133433980784, 0], [0.0057443621103518165, 0.4066853943173458, 0.5875702435723024]]\n\nInstance: [4.8, 3.1, 1.6, 0.2]\nError: 2.5069837477428005\nOutput: [0.769788106451487, 0.14869815874542242, 0.0815137348030905]\nHidden Layer: [[4.8, 3.1, 1.6, 0.2], [2.543085882582636, 1.0714842048260111, 0, 0], [0.06407156137997505, 0, 0, 0], [0.769788106451487, 0.14869815874542242, 0.0815137348030905]]\n\nInstance: [7.9, 3.8, 6.4, 2.0]\nError: 0.9522429894311278\nOutput: [0.0004932146022831905, 0.38587453954670636, 0.6136322458510104]\nHidden Layer: [[7.9, 3.8, 6.4, 2.0], [1.1197505840013715, 6.125820740323594, 0, 0], [2.348863793705001, 0, 4.674271104921227, 0], [0.0004932146022831905, 0.38587453954670636, 0.6136322458510104]]\n\nInstance: [5.5, 2.5, 4.0, 1.3]\nError: 0.7475098323464018\nOutput: [0.019837153723175863, 0.4735442904248449, 0.5066185558519792]\nHidden Layer: [[5.5, 2.5, 4.0, 1.3], [0.9095191759268471, 3.7815184709040333, 0, 0], [1.33962787322554, 0, 2.7495210330411997, 0], [0.019837153723175863, 0.4735442904248449, 0.5066185558519792]]\n\nInstance: [6.2, 2.9, 4.3, 1.3]\nError: 0.7114017376877456\nOutput: [0.018104306008423984, 0.49095552404292764, 0.49094016994864836]\nHidden Layer: [[6.2, 2.9, 4.3, 1.3], [1.2684589683964578, 4.0960195160152555, 0, 0], [1.4558347880436693, 0, 2.757279842475635, 0], [0.018104306008423984, 0.49095552404292764, 0.49094016994864836]]\n\nInstance: [6.8, 2.8, 4.8, 1.4]\nError: 5.282763551083734\nOutput: [0.005078377028155602, 0.4554018622267741, 0.5395197607450702]\nHidden Layer: [[6.8, 2.8, 4.8, 1.4], [1.1962684424731171, 4.80549941631809, 0, 0], [1.7691493580749724, 0, 3.4426352278296593, 0], [0.005078377028155602, 0.4554018622267741, 0.5395197607450702]]\n\nInstance: [7.6, 3.0, 6.6, 2.1]\nError: 9.274730356999108\nOutput: [9.376392629500143e-05, 0.30897775154161355, 0.6909284845320914]\nHidden Layer: [[7.6, 3.0, 6.6, 2.1], [0.4460481163526549, 6.5964618938056265, 0, 0], [2.593010966716695, 0, 5.602820153972492, 0], [9.376392629500143e-05, 0.30897775154161355, 0.6909284845320914]]\n\nInstance: [5.4, 3.7, 1.5, 0.2]\nError: 0.2502044359753803\nOutput: [0.7786415844472082, 0.1409682042100204, 0.08039021134277138]\nHidden Layer: [[5.4, 3.7, 1.5, 0.2], [3.188427433731631, 0.9142994320864211, 0, 0], [0, 0, 0, 0], [0.7786415844472082, 0.1409682042100204, 0.08039021134277138]]\n\nInstance: [6.4, 2.9, 4.3, 1.3]\nError: 4.019887611305656\nOutput: [0.01795498276318018, 0.4961666059382341, 0.48587841129858583]\nHidden Layer: [[6.4, 2.9, 4.3, 1.3], [1.3683496815656822, 4.17301375750343, 0, 0], [1.483586681390611, 0, 2.7500789894303463, 0], [0.01795498276318018, 0.4961666059382341, 0.48587841129858583]]\n\nInstance: [4.8, 3.4, 1.9, 0.2]\nError: 2.4977628416320825\nOutput: [0.7635277944686718, 0.1542033641999276, 0.08226884133140062]\nHidden Layer: [[4.8, 3.4, 1.9, 0.2], [2.5048477002644485, 1.1673909179881603, 0, 0], [0.10807731986563102, 0, 0, 0], [0.7635277944686718, 0.1542033641999276, 0.08226884133140062]]\nAverage of Error:  2.714320248358729\nFinal Weight:\n[[list([-0.31813638492303814, -0.5513254195908769, 0.285, 0.435])\n  list([0.499563682449436, 0.38498742570879496, -0.335, -0.18])\n  list([0.4757196459833055, -0.5089977344788427, -0.46, -0.395])\n  list([-0.603557887195607, 0.8291198179338322, -0.2, -0.495])\n  list([-0.22807308091946568, 0.13373149770526582, 0.475, 0.3])]\n [list([-0.2551044323527735, -0.275, 0.07659305795152159, -0.455])\n  list([-0.05780854136217735, -0.425, -0.7578941592397257, 0.185])\n  list([0.4357522916195159, -0.44, 0.8896241061164254, -0.49])\n  list([-0.05, 0.475, 0.04, -0.025]) list([0.45, 0.345, -0.22, 0.255])]\n [list([1.097555818893673, -0.6124984447564394, -1.1750573741372337])\n  list([-0.530733380771507, 0.48093889114486243, -0.1352055103733556])\n  list([-0.275, -0.075, 0.175])\n  list([-0.9451077331536862, 0.3368701643930904, 0.8682375687605957])\n  list([0.345, -0.075, -0.315])]]\n\nEnd of epoch - 100\n-------------------------------\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"#MLP SKLEARN\nprint(\"MLP Sklearn\")\nclf = MLPClassifier(hidden_layer_sizes=(4, 4), activation='relu',\n                    max_iter=100, batch_size=10, learning_rate_init=0.0001, tol=0.0001)\nclf.fit(iris.data, iris.target)\npred = clf.predict(x)\n\nprint(\"Accuracy: \" + str(metrics.accuracy_score(y, pred)))\nprint(\"F1: \" + str(metrics.f1_score(y, pred, average='weighted')))\nprint(\"Confusion Matrix: \")\n\nmetrics.confusion_matrix(y, pred)\n\n# Tugas B\nf = open(\"output/iris.json\", \"r\")\ndata = json.load(f)\ncase = data[\"case\"]\n\n# Input\ninp = case[\"input\"]\n\n# Activation\nactivation = []\nfor i in case[\"model\"][\"layers\"]:\n    activation.append(i['activation_function'])\n\n# Neuron\nneuron = [case[\"model\"][\"input_size\"]]\nfor i in case[\"model\"][\"layers\"]:\n    neuron.append(i['number_of_neurons'])\n\n# Weight\nweight = case['weights']\n\n# Expected Output\nexpect = data[\"expect\"]\neoutput = expect[\"output\"]\nsse = expect[\"max_sse\"]\nf.close()\n\ninstance = 0\noutput = []\nfor item in inp:\n    h = [item]\n    for i in range(len(weight)):\n        h.append([0 for j in range(neuron[i + 1])])\n        net = [0 for j in range(neuron[i + 1])]\n        for k in range(len(weight[i][0])):\n            net[k] += weight[i][0][k]\n        for j in range(1, len(weight[i])):\n            for k in range(len(weight[i][j])):\n                net[k] += h[i][j - 1] * weight[i][j][k]\n        \n        if activation[i] == \"softmax\":\n            h[i+1] = eval(activation[i] + \"({})\".format(net))\n        else:\n            for j in range(len(net)):\n                h[i + 1][j] = eval(activation[i] + \"({})\".format(net[j]))\n    output.append(h[len(h)-1])\n    instance += 1\n\nprint(\"Class ANN\")\ntrue = []\npred = []\nfor i in range(len(output)):\n    true.append(eoutput[i].index(max(eoutput[i])))\n    pred.append(output[i].index(max(output[i])))\nprint(\"Accuracy:\", metrics.accuracy_score(true, pred))\nprint(\"F1 Score:\", metrics.f1_score(true, pred, average='weighted'))","metadata":{"cell_id":"2a81bacb90a84525b935623c204592a0","source_hash":"c585ebfb","execution_start":1683295141968,"execution_millis":1476,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"MLP Sklearn\nAccuracy: 0.6666666666666666\nF1: 0.5555555555555555\nConfusion Matrix: \nClass ANN\nAccuracy: 0.7666666666666667\nF1 Score: 0.7340930674264008\n/shared-libs/python3.9/py/lib/python3.9/site-packages/sklearn/neural_network/_multilayer_perceptron.py:702: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (100) reached and the optimization hasn't converged yet.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"hiddenLayer = len(neuron)-2\nprint(\"x(\"+ str(neuron[0]) +\")\", end=\" --> \")\nfor i in range(hiddenLayer):\n    print(\"h\"+str(i+1)+\"(\"+ str(neuron[i+1]) +\")\", end=\" --> \")\nprint(\"y(\"+ str(neuron[len(neuron)-1]) +\")\\n\")\n\nprint(\"Weight:\")\nprint(\"\\tInput layer:\")\nif (hiddenLayer == 0):\n    for i in range(int(neuron[1])):\n        print(\"\\t* b -> y(\"+str(i+1)+\") = \"+ str(weight[0][0][i]))\n    for i in range(int(neuron[0])):\n        for j in range(int(neuron[1])):\n            print(\"\\t* x(\"+ str(i+1) +\") -> y(\"+ str(j+1)+\") = \"+ str(weight[0][i+1][j]))\nelse:\n    for i in range(int(neuron[1])):\n        print(\"\\t* b -> h1(\"+str(i+1)+\") = \"+ str(weight[0][0][i]))\n    for i in range(int(neuron[0])):\n        for j in range(int(neuron[1])):\n            print(\"\\t* x(\"+ str(i+1) +\") -> h1(\"+ str(j+1)+\") = \"+ str(weight[0][i+1][j]))\n\nif hiddenLayer != 0:\n    print(\"\\n\\tHidden Layer:\")\n    for i in range(hiddenLayer):\n        if (i+1 == hiddenLayer):\n            print(\"\\th\"+str(i+1))\n            for m in range(int(neuron[i+2])):\n                print(\"\\t* b -> y(\"+ str(m+1) + \") = \"+ str(weight[i+1][0][m]))\n            for n in range(int(neuron[i+1])):\n                for k in range(int(neuron[i+2])):\n                    print(\"\\t* h\"+ str(i+1) + \"(\" + str(n+1) + \") -> y(\"+ str(k+1) +\") = \"+ str(weight[i+1][n+1][k]))\n        else:\n            print(\"\\th\"+str(i+1))\n            for m in range(int(neuron[i+2])):\n                print(\"\\t* b -> h\"+ str(i+2) + \"(\" + str(m+1)+\") = \"+ str(weight[i+1][0][m]))\n            for n in range(int(neuron[i+1])):\n                for k in range(int(neuron[i+2])):\n                    print(\"\\t* h\"+ str(i+1) + \"(\" + str(n+1) +\") -> h\"+ str(i+2) + \"(\" + str(k+1)+\") = \"+ str(weight[i+1][n+1][k]))\n\nprint(\"\\nActivation function:\")\nfor i in range(len(activation)):\n    if i == 0:\n        if len(activation) == 1:\n            print(\"x --> y = \" + activation[i])\n        else:\n            print(\"x --> h1 = \" + activation[i])\n    elif i == len(activation)-1:\n        print(\"h\"+ str(i) +\" --> y = \" + activation[i])\n    else:\n        print(\"h\"+ str(i) +\" --> h\"+ str(i+1) + \" = \" + activation[i])","metadata":{"cell_id":"fd6c0ec420f54f5d95055809298e0308","source_hash":"c68203a3","execution_start":1683295773939,"execution_millis":1,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","text":"x(4) --> h1(4) --> h2(4) --> y(3)\n\nWeight:\n\tInput layer:\n\t* b -> h1(1) = -0.31813638492303814\n\t* b -> h1(2) = -0.5513254195908769\n\t* b -> h1(3) = 0.285\n\t* b -> h1(4) = 0.435\n\t* x(1) -> h1(1) = 0.499563682449436\n\t* x(1) -> h1(2) = 0.38498742570879496\n\t* x(1) -> h1(3) = -0.335\n\t* x(1) -> h1(4) = -0.18\n\t* x(2) -> h1(1) = 0.4757196459833055\n\t* x(2) -> h1(2) = -0.5089977344788427\n\t* x(2) -> h1(3) = -0.46\n\t* x(2) -> h1(4) = -0.395\n\t* x(3) -> h1(1) = -0.603557887195607\n\t* x(3) -> h1(2) = 0.8291198179338322\n\t* x(3) -> h1(3) = -0.2\n\t* x(3) -> h1(4) = -0.495\n\t* x(4) -> h1(1) = -0.22807308091946568\n\t* x(4) -> h1(2) = 0.13373149770526582\n\t* x(4) -> h1(3) = 0.475\n\t* x(4) -> h1(4) = 0.3\n\n\tHidden Layer:\n\th1\n\t* b -> h2(1) = -0.2551044323527735\n\t* b -> h2(2) = -0.275\n\t* b -> h2(3) = 0.07659305795152159\n\t* b -> h2(4) = -0.455\n\t* h1(1) -> h2(1) = -0.05780854136217735\n\t* h1(1) -> h2(2) = -0.425\n\t* h1(1) -> h2(3) = -0.7578941592397257\n\t* h1(1) -> h2(4) = 0.185\n\t* h1(2) -> h2(1) = 0.4357522916195159\n\t* h1(2) -> h2(2) = -0.44\n\t* h1(2) -> h2(3) = 0.8896241061164254\n\t* h1(2) -> h2(4) = -0.49\n\t* h1(3) -> h2(1) = -0.05\n\t* h1(3) -> h2(2) = 0.475\n\t* h1(3) -> h2(3) = 0.04\n\t* h1(3) -> h2(4) = -0.025\n\t* h1(4) -> h2(1) = 0.45\n\t* h1(4) -> h2(2) = 0.345\n\t* h1(4) -> h2(3) = -0.22\n\t* h1(4) -> h2(4) = 0.255\n\th2\n\t* b -> y(1) = 1.097555818893673\n\t* b -> y(2) = -0.6124984447564394\n\t* b -> y(3) = -1.1750573741372337\n\t* h2(1) -> y(1) = -0.530733380771507\n\t* h2(1) -> y(2) = 0.48093889114486243\n\t* h2(1) -> y(3) = -0.1352055103733556\n\t* h2(2) -> y(1) = -0.275\n\t* h2(2) -> y(2) = -0.075\n\t* h2(2) -> y(3) = 0.175\n\t* h2(3) -> y(1) = -0.9451077331536862\n\t* h2(3) -> y(2) = 0.3368701643930904\n\t* h2(3) -> y(3) = 0.8682375687605957\n\t* h2(4) -> y(1) = 0.345\n\t* h2(4) -> y(2) = -0.075\n\t* h2(4) -> y(3) = -0.315\n\nActivation function:\nx --> h1 = relu\nh1 --> h2 = relu\nh2 --> y = softmax\n","output_type":"stream"}],"execution_count":15},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e02db8a3-47d5-4c48-a321-8f1424eda79b' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"deepnote":{},"orig_nbformat":2,"deepnote_notebook_id":"18815545abc14e72a71312f28393b179","deepnote_persisted_session":{"createdAt":"2023-05-05T11:01:49.941Z"},"deepnote_execution_queue":[]}}